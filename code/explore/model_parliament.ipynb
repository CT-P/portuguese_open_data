{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tokenizedDF= False\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "stop_words_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "snowball = nltk.stem.snowball.SnowballStemmer('portuguese')\n",
    "right=[ 'PSD',  'CDS-PP', 'CH','IL','CDS']\n",
    "left=[ 'PS', 'BE', 'PCP', 'PAN', 'PEV','L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normlizeTokens(tokenLst, stopwordLst = None, stemmer = None):\n",
    "    #We can use a generator here as we just need to iterate over it\n",
    "\n",
    "    #Lowering the case and removing non-words\n",
    "    workingIter = (w.lower() for w in tokenLst if w.isalpha())\n",
    "\n",
    "    #Now we can use the semmer, if provided\n",
    "    if stemmer is not None:\n",
    "        workingIter = (stemmer.stem(w) for w in workingIter)\n",
    "         \n",
    "    #And remove the stopwords\n",
    "    if stopwordLst is not None:\n",
    "        workingIter = (w for w in workingIter if w not in stopwordLst)\n",
    "    #We will return a list with the stopwords removed\n",
    "    return list(workingIter)\n",
    "\n",
    "def create_tokenized_dataset(df_input):\n",
    "    # 1 create token column: tokens\n",
    "    df_input['tokens']=df_input['speech'].apply(lambda x: nltk.word_tokenize(x))\n",
    "    # 2 create token without stopwords and stemmer: tokens_stemer_stop. 16min\n",
    "    df_input['tokens_stemer_stop'] = df_input['tokens'].apply(lambda x: normlizeTokens(x, stopwordLst = stop_words_nltk, stemmer = snowball))\n",
    "    \n",
    "    # 3 extract very frequent or rare words: token_cleaned\n",
    "    flat_tokens=[item for sublist in df_input['tokens_stemer_stop'] for item in sublist]\n",
    "    aux_c=Counter(flat_tokens)\n",
    "        \n",
    "    extrat_common=['par', 'nao', 'sr', 'deput', 'govern', 'muit', 'pel', 'president','tod','tamb','srs','sras','pod','part','psd','sao','aplaus','ja','porqu','faz','ha','diz','quer','pais','sobr','bem','nest']\n",
    "    extract_rare=[x[0] for x in aux_c.most_common()[-30:]]\n",
    "\n",
    "    df_input['tokens_cleaned'] = df_input['tokens_stemer_stop'].apply(lambda x : [i for i in x if not i in extrat_common])\n",
    "    df_input['tokens_cleaned'] = df_input['tokens_cleaned'].apply(lambda x : [i for i in x if not i in extract_rare])\n",
    "    df_input.to_pickle('dftok.pkl')  \n",
    "    return df_input\n",
    "\n",
    "def generate_N_grams(text,ngram=1):\n",
    "  words=[word for word in text]  \n",
    "  temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "  ans=[' '.join(ngram) for ngram in temp]\n",
    "  return ans\n",
    "\n",
    "def create_grams(df_frame, n):\n",
    "    grams_d={1: 'uni_grams', 2: 'bi_grams', 3: 'tri_grams'}\n",
    "    df_frame[grams_d[n]] = df_frame['tokens_cleaned'].apply(lambda x: generate_N_grams(x,n))\n",
    "    return df_frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_tokenizedDF==True:\n",
    "    df_input = pd.read_pickle('parliament_fdf.pkl')  \n",
    "    df_tok=create_tokenized_dataset(df_input)\n",
    "else:\n",
    "    df_tok = pd.read_pickle('dftok.pkl')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok=create_grams(df_tok, 2)\n",
    "df_tok=create_grams(df_tok, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "      <th>filename</th>\n",
       "      <th>number</th>\n",
       "      <th>session</th>\n",
       "      <th>term</th>\n",
       "      <th>Date</th>\n",
       "      <th>link</th>\n",
       "      <th>party</th>\n",
       "      <th>speaker_ntime</th>\n",
       "      <th>genre</th>\n",
       "      <th>len_speech</th>\n",
       "      <th>year</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_stemer_stop</th>\n",
       "      <th>tokens_cleaned</th>\n",
       "      <th>bi_grams</th>\n",
       "      <th>tri_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>josemanuelpureza</td>\n",
       "      <td>muito bem</td>\n",
       "      <td>darl13sl01n001.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>BE</td>\n",
       "      <td>891.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>[muito, bem]</td>\n",
       "      <td>[muit, bem]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teresalealcoelho</td>\n",
       "      <td>muito bem</td>\n",
       "      <td>darl13sl01n001.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>PSD</td>\n",
       "      <td>87.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>[muito, bem]</td>\n",
       "      <td>[muit, bem]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luismontenegro</td>\n",
       "      <td>muito bom dia a todos sras e srs deputados cum...</td>\n",
       "      <td>darl13sl01n001.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>PSD</td>\n",
       "      <td>694.0</td>\n",
       "      <td>M</td>\n",
       "      <td>204</td>\n",
       "      <td>2015</td>\n",
       "      <td>[muito, bom, dia, a, todos, sras, e, srs, depu...</td>\n",
       "      <td>[muit, bom, dia, tod, sras, srs, deput, cumpr,...</td>\n",
       "      <td>[bom, dia, cumpr, prax, parlament, cabem, lid,...</td>\n",
       "      <td>[bom dia, dia cumpr, cumpr prax, prax parlamen...</td>\n",
       "      <td>[bom dia cumpr, dia cumpr prax, cumpr prax par...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            speaker                                             speech  \\\n",
       "0  josemanuelpureza                                         muito bem    \n",
       "1  teresalealcoelho                                         muito bem    \n",
       "2    luismontenegro  muito bom dia a todos sras e srs deputados cum...   \n",
       "\n",
       "             filename  number  session  term        Date  \\\n",
       "0  darl13sl01n001.txt       1        1    13  2015-10-23   \n",
       "1  darl13sl01n001.txt       1        1    13  2015-10-23   \n",
       "2  darl13sl01n001.txt       1        1    13  2015-10-23   \n",
       "\n",
       "                                                link party  speaker_ntime  \\\n",
       "0  https://debates.parlamento.pt/catalogo/r3/dar/...    BE          891.0   \n",
       "1  https://debates.parlamento.pt/catalogo/r3/dar/...   PSD           87.0   \n",
       "2  https://debates.parlamento.pt/catalogo/r3/dar/...   PSD          694.0   \n",
       "\n",
       "  genre  len_speech  year                                             tokens  \\\n",
       "0     M           2  2015                                       [muito, bem]   \n",
       "1     F           2  2015                                       [muito, bem]   \n",
       "2     M         204  2015  [muito, bom, dia, a, todos, sras, e, srs, depu...   \n",
       "\n",
       "                                  tokens_stemer_stop  \\\n",
       "0                                        [muit, bem]   \n",
       "1                                        [muit, bem]   \n",
       "2  [muit, bom, dia, tod, sras, srs, deput, cumpr,...   \n",
       "\n",
       "                                      tokens_cleaned  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [bom, dia, cumpr, prax, parlament, cabem, lid,...   \n",
       "\n",
       "                                            bi_grams  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [bom dia, dia cumpr, cumpr prax, prax parlamen...   \n",
       "\n",
       "                                           tri_grams  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  [bom dia cumpr, dia cumpr prax, cumpr prax par...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tok.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#political polarization functions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_frequency_table_grams(n_gram=1, indf=None, right_parties=right, left_parties=left):\n",
    "    grams_d={1: 'uni_grams', 2: 'bi_grams', 3: 'tri_grams'}\n",
    "   \n",
    "\n",
    "    r_grams=[item for sublist in indf[indf.party.isin(right)][grams_d[n_gram]] for item in sublist]\n",
    "    l_grams=[item for sublist in indf[indf.party.isin(left)][grams_d[n_gram]] for item in sublist]\n",
    "\n",
    "    total_counter = Counter([item for sublist in indf[grams_d[n_gram]] for item in sublist])\n",
    "    right_counter = Counter(r_grams)\n",
    "    left_counter = Counter(l_grams)\n",
    "\n",
    "    df_all = pd.DataFrame.from_dict(total_counter, orient='index').reset_index()\n",
    "    df_all.columns=['phrase','count']\n",
    "    df_all['count_right']=[right_counter[x] for x in df_all.phrase]\n",
    "    df_all['count_left']=[left_counter[x] for x in df_all.phrase]\n",
    "\n",
    "\n",
    "    df_all['count_left_total']=sum(left_counter.values())\n",
    "    df_all['count_right_total']=sum(right_counter.values())\n",
    "    # frequency of every words except the given one (by row)\n",
    "    #Jensen et al. (2012),p.10 \n",
    "    #f-pck is the frequency of all phrases used in Con­gress c by party k excluding phrase p\n",
    "    df_all['f_right_minus']=( df_all['count_right_total']-df_all['count_right'])/df_all['count_right_total']\n",
    "    df_all['f_left_minus']=( df_all['count_left_total']-df_all['count_left'])/df_all['count_left_total']\n",
    "\n",
    "    df_all['f_right']=df_all['count_right']/df_all['count_right_total']\n",
    "    df_all['f_right_norm'] = (df_all['f_right'] - df_all['f_right'].min()) / (df_all['f_right'].max() - df_all['f_right'].min())  \n",
    "    df_all['f_left']=df_all['count_left']/df_all['count_left_total']\n",
    "    df_all['f_left_norm'] = (df_all['f_left'] - df_all['f_left'].min()) / (df_all['f_left'].max() - df_all['f_left'].min())  \n",
    "\n",
    "    df_all['f_right_minus_norm']=(df_all['f_right_minus'] - df_all['f_right_minus'].min()) / (df_all['f_right_minus'].max() - df_all['f_right_minus'].min()) \n",
    "    df_all['f_left_minus_norm']=(df_all['f_left_minus'] - df_all['f_left_minus'].min()) / (df_all['f_left_minus'].max() - df_all['f_left_minus'].min()) \n",
    "\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def calculate_pearson(df_all):\n",
    "    aa=df_all['f_right_norm']*df_all['f_left_minus_norm'] \n",
    "    bb=df_all['f_left_norm']*df_all['f_right_minus_norm']\n",
    "    cc=aa-bb\n",
    "    dd=cc*cc\n",
    "    d11=df_all['f_right_norm']+df_all['f_left_norm']\n",
    "    d22=df_all['f_right_norm']+df_all['f_right_minus_norm']\n",
    "    d33=df_all['f_left_norm']+df_all['f_left_minus_norm']\n",
    "    d44=df_all['f_right_minus_norm']+df_all['f_left_minus_norm']\n",
    "    denom=d11*d22*d33*d44\n",
    "    pp=dd/denom\n",
    "    return pp\n",
    "\n",
    "def create_phrase_partisanship(df):\n",
    "    aa=df['f_right_norm']+df['f_left_norm']\n",
    "    df['rho']=df['f_right_norm']/aa\n",
    "    \n",
    "    df['gram_partisanship']= 0.5 * df['f_right_norm']*df['rho']+0.5 *df['f_right_norm']*(1-df['rho'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_polarization_correlation(df):\n",
    "    \n",
    "    aa=df['f_left_norm']*-1\n",
    "    bb= df['f_right_norm']*1\n",
    "    df['beta_polarization']=aa+bb\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq=create_frequency_table_grams(n_gram=3, indf=df_tok, right_parties=right, left_parties=left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq['pearson_quad']=calculate_pearson(df_freq)\n",
    "trigrams_table=df_freq[df_freq.pearson_quad>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>count</th>\n",
       "      <th>count_right</th>\n",
       "      <th>count_left</th>\n",
       "      <th>count_left_total</th>\n",
       "      <th>count_right_total</th>\n",
       "      <th>f_right_minus</th>\n",
       "      <th>f_left_minus</th>\n",
       "      <th>f_right</th>\n",
       "      <th>f_right_norm</th>\n",
       "      <th>f_left</th>\n",
       "      <th>f_left_norm</th>\n",
       "      <th>f_right_minus_norm</th>\n",
       "      <th>f_left_minus_norm</th>\n",
       "      <th>pearson_quad</th>\n",
       "      <th>rho</th>\n",
       "      <th>gram_partisanship</th>\n",
       "      <th>beta_polarization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>servic nacional saud</td>\n",
       "      <td>4454</td>\n",
       "      <td>1032</td>\n",
       "      <td>3422</td>\n",
       "      <td>3230452</td>\n",
       "      <td>2008118</td>\n",
       "      <td>0.999486</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.266529</td>\n",
       "      <td>1.059294e-03</td>\n",
       "      <td>0.606953</td>\n",
       "      <td>0.733471</td>\n",
       "      <td>0.393047</td>\n",
       "      <td>0.117774</td>\n",
       "      <td>0.305134</td>\n",
       "      <td>0.133264</td>\n",
       "      <td>-0.340424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>bloc esquerd pcp</td>\n",
       "      <td>603</td>\n",
       "      <td>491</td>\n",
       "      <td>112</td>\n",
       "      <td>3230452</td>\n",
       "      <td>2008118</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.126808</td>\n",
       "      <td>3.467007e-05</td>\n",
       "      <td>0.019865</td>\n",
       "      <td>0.873192</td>\n",
       "      <td>0.980135</td>\n",
       "      <td>0.042073</td>\n",
       "      <td>0.864561</td>\n",
       "      <td>0.063404</td>\n",
       "      <td>0.106943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38698</th>\n",
       "      <td>apresent declaraca vot</td>\n",
       "      <td>1186</td>\n",
       "      <td>475</td>\n",
       "      <td>711</td>\n",
       "      <td>3230452</td>\n",
       "      <td>2008118</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.122676</td>\n",
       "      <td>2.200930e-04</td>\n",
       "      <td>0.126109</td>\n",
       "      <td>0.877324</td>\n",
       "      <td>0.873891</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.493101</td>\n",
       "      <td>0.061338</td>\n",
       "      <td>-0.003433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68917</th>\n",
       "      <td>sra secret estad</td>\n",
       "      <td>854</td>\n",
       "      <td>473</td>\n",
       "      <td>381</td>\n",
       "      <td>3230452</td>\n",
       "      <td>2008118</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.122159</td>\n",
       "      <td>1.179402e-04</td>\n",
       "      <td>0.067577</td>\n",
       "      <td>0.877841</td>\n",
       "      <td>0.932423</td>\n",
       "      <td>0.008674</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.061080</td>\n",
       "      <td>0.054582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132062</th>\n",
       "      <td>caix geral deposit</td>\n",
       "      <td>947</td>\n",
       "      <td>458</td>\n",
       "      <td>489</td>\n",
       "      <td>3230452</td>\n",
       "      <td>2008118</td>\n",
       "      <td>0.999772</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.118285</td>\n",
       "      <td>1.513720e-04</td>\n",
       "      <td>0.086733</td>\n",
       "      <td>0.881715</td>\n",
       "      <td>0.913267</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.576950</td>\n",
       "      <td>0.059143</td>\n",
       "      <td>0.031552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335836</th>\n",
       "      <td>pretend ate implod</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3230452</td>\n",
       "      <td>2008118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.095542e-07</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335837</th>\n",
       "      <td>ate implod portant</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3230452</td>\n",
       "      <td>2008118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.095542e-07</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335838</th>\n",
       "      <td>implod portant aquil</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3230452</td>\n",
       "      <td>2008118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.095542e-07</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335839</th>\n",
       "      <td>portant aquil fiz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3230452</td>\n",
       "      <td>2008118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.095542e-07</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087900</th>\n",
       "      <td>emissa tal cas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3230452</td>\n",
       "      <td>2008118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.095542e-07</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4175799 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         phrase  count  count_right  count_left  \\\n",
       "4238       servic nacional saud   4454         1032        3422   \n",
       "2120           bloc esquerd pcp    603          491         112   \n",
       "38698    apresent declaraca vot   1186          475         711   \n",
       "68917          sra secret estad    854          473         381   \n",
       "132062       caix geral deposit    947          458         489   \n",
       "...                         ...    ...          ...         ...   \n",
       "2335836      pretend ate implod      1            0           1   \n",
       "2335837      ate implod portant      1            0           1   \n",
       "2335838    implod portant aquil      1            0           1   \n",
       "2335839       portant aquil fiz      1            0           1   \n",
       "2087900          emissa tal cas      1            0           1   \n",
       "\n",
       "         count_left_total  count_right_total  f_right_minus  f_left_minus  \\\n",
       "4238              3230452            2008118       0.999486      0.998941   \n",
       "2120              3230452            2008118       0.999755      0.999965   \n",
       "38698             3230452            2008118       0.999763      0.999780   \n",
       "68917             3230452            2008118       0.999764      0.999882   \n",
       "132062            3230452            2008118       0.999772      0.999849   \n",
       "...                   ...                ...            ...           ...   \n",
       "2335836           3230452            2008118       1.000000      1.000000   \n",
       "2335837           3230452            2008118       1.000000      1.000000   \n",
       "2335838           3230452            2008118       1.000000      1.000000   \n",
       "2335839           3230452            2008118       1.000000      1.000000   \n",
       "2087900           3230452            2008118       1.000000      1.000000   \n",
       "\n",
       "          f_right  f_right_norm        f_left  f_left_norm  \\\n",
       "4238     0.000514      0.266529  1.059294e-03     0.606953   \n",
       "2120     0.000245      0.126808  3.467007e-05     0.019865   \n",
       "38698    0.000237      0.122676  2.200930e-04     0.126109   \n",
       "68917    0.000236      0.122159  1.179402e-04     0.067577   \n",
       "132062   0.000228      0.118285  1.513720e-04     0.086733   \n",
       "...           ...           ...           ...          ...   \n",
       "2335836  0.000000      0.000000  3.095542e-07     0.000177   \n",
       "2335837  0.000000      0.000000  3.095542e-07     0.000177   \n",
       "2335838  0.000000      0.000000  3.095542e-07     0.000177   \n",
       "2335839  0.000000      0.000000  3.095542e-07     0.000177   \n",
       "2087900  0.000000      0.000000  3.095542e-07     0.000177   \n",
       "\n",
       "         f_right_minus_norm  f_left_minus_norm  pearson_quad       rho  \\\n",
       "4238               0.733471           0.393047      0.117774  0.305134   \n",
       "2120               0.873192           0.980135      0.042073  0.864561   \n",
       "38698              0.877324           0.873891      0.000027  0.493101   \n",
       "68917              0.877841           0.932423      0.008674  0.643836   \n",
       "132062             0.881715           0.913267      0.002705  0.576950   \n",
       "...                     ...                ...           ...       ...   \n",
       "2335836            1.000000           0.999823      0.000089  0.000000   \n",
       "2335837            1.000000           0.999823      0.000089  0.000000   \n",
       "2335838            1.000000           0.999823      0.000089  0.000000   \n",
       "2335839            1.000000           0.999823      0.000089  0.000000   \n",
       "2087900            1.000000           0.999823      0.000089  0.000000   \n",
       "\n",
       "         gram_partisanship  beta_polarization  \n",
       "4238              0.133264          -0.340424  \n",
       "2120              0.063404           0.106943  \n",
       "38698             0.061338          -0.003433  \n",
       "68917             0.061080           0.054582  \n",
       "132062            0.059143           0.031552  \n",
       "...                    ...                ...  \n",
       "2335836           0.000000          -0.000177  \n",
       "2335837           0.000000          -0.000177  \n",
       "2335838           0.000000          -0.000177  \n",
       "2335839           0.000000          -0.000177  \n",
       "2087900           0.000000          -0.000177  \n",
       "\n",
       "[4175799 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_table=create_phrase_partisanship(trigrams_table)\n",
    "trigrams_table=create_polarization_correlation(trigrams_table)\n",
    "trigrams_table.sort_values(by='gram_partisanship',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_tok['gram_polarization']=df_tok.apply(lambda x : list(trigrams_table[trigrams_table.phrase==item].gram_partisanship.values[0]   for item in x.tri_grams if len(trigrams_table[trigrams_table.phrase==item].gram_partisanship.values)>0), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_polarization_model(declaracoes2,right,left):\n",
    "    dfg3=create_frequency_table_grams(n_gram=3, indf=declaracoes2, right_parties=right, left_parties=left)\n",
    "    dfg3['pearson_quad']=calculate_pearson(dfg3)\n",
    "    trigrams_table=dfg3[dfg3.pearson_quad>0]\n",
    "    trigrams_table=create_phrase_partisanship(trigrams_table)\n",
    "    trigrams_table=create_polarization_correlation(trigrams_table)\n",
    "    final_df = trigrams_table.sort_values(by=['gram_partisanship'], ascending=False)\n",
    "    return final_df\n",
    "\n",
    "def create_200r(df_mainf):\n",
    "    indexes_no_applause=[n for n,x in enumerate(df_mainf.phrase) if 'aplausos' not in x]\n",
    "    df_mainf=df_mainf.iloc[indexes_no_applause]\n",
    "\n",
    "    tri_final = df_mainf[0:200].append(df_mainf[-200:], ignore_index=True)\n",
    "    return tri_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddb3f830e79c6f8e791b80246b7047706826e249abf27510d15251ed3cae5420"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
