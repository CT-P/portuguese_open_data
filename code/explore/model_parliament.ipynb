{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tokenizedDF= False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "stop_words_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "snowball = nltk.stem.snowball.SnowballStemmer('portuguese')\n",
    "right=[ 'PSD',  'CDS-PP', 'CH','IL','CDS']\n",
    "left=[ 'PS', 'BE', 'PCP', 'PAN', 'PEV','L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normlizeTokens(tokenLst, stopwordLst = None, stemmer = None):\n",
    "    #We can use a generator here as we just need to iterate over it\n",
    "\n",
    "    #Lowering the case and removing non-words\n",
    "    workingIter = (w.lower() for w in tokenLst if w.isalpha())\n",
    "\n",
    "    #Now we can use the semmer, if provided\n",
    "    if stemmer is not None:\n",
    "        workingIter = (stemmer.stem(w) for w in workingIter)\n",
    "         \n",
    "    #And remove the stopwords\n",
    "    if stopwordLst is not None:\n",
    "        workingIter = (w for w in workingIter if w not in stopwordLst)\n",
    "    #We will return a list with the stopwords removed\n",
    "    return list(workingIter)\n",
    "\n",
    "def create_tokenized_dataset(df_input):\n",
    "    # 1 create token column: tokens\n",
    "    df_input['tokens']=df_input['speech'].apply(lambda x: nltk.word_tokenize(x))\n",
    "    # 2 create token without stopwords and stemmer: tokens_stemer_stop. 16min\n",
    "    df_input['tokens_stemer_stop'] = df_input['tokens'].apply(lambda x: normlizeTokens(x, stopwordLst = stop_words_nltk, stemmer = snowball))\n",
    "    \n",
    "    # 3 extract very frequent or rare words: token_cleaned\n",
    "    flat_tokens=[item for sublist in df_input['tokens_stemer_stop'] for item in sublist]\n",
    "    aux_c=Counter(flat_tokens)\n",
    "        \n",
    "    extrat_common=['par', 'nao', 'sr', 'deput', 'govern', 'muit', 'pel', 'president','tod','tamb','srs','sras','pod','part','psd','sao','aplaus','ja','porqu','faz','ha','diz','quer','pais','sobr','bem','nest']\n",
    "    extract_rare=[x[0] for x in aux_c.most_common()[-30:]]\n",
    "\n",
    "    df_input['tokens_cleaned'] = df_input['tokens_stemer_stop'].apply(lambda x : [i for i in x if not i in extrat_common])\n",
    "    df_input['tokens_cleaned'] = df_input['tokens_cleaned'].apply(lambda x : [i for i in x if not i in extract_rare])\n",
    "    df_input.to_pickle('dftok.pkl')  \n",
    "    return df_input\n",
    "\n",
    "def generate_N_grams(text,ngram=1):\n",
    "  words=[word for word in text]  \n",
    "  temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "  ans=[' '.join(ngram) for ngram in temp]\n",
    "  return ans\n",
    "\n",
    "def create_grams(df_frame, n):\n",
    "    grams_d={1: 'uni_grams', 2: 'bi_grams', 3: 'tri_grams'}\n",
    "    df_frame[grams_d[n]] = df_frame['tokens_cleaned'].apply(lambda x: generate_N_grams(x,n))\n",
    "    return df_frame \n",
    "\n",
    "#political polarization functions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_frequency_table_grams(n_gram=1, indf=None, right_parties=right, left_parties=left):\n",
    "    grams_d={1: 'uni_grams', 2: 'bi_grams', 3: 'tri_grams'}\n",
    "   \n",
    "\n",
    "    r_grams=[item for sublist in indf[indf.party.isin(right)][grams_d[n_gram]] for item in sublist]\n",
    "    l_grams=[item for sublist in indf[indf.party.isin(left)][grams_d[n_gram]] for item in sublist]\n",
    "\n",
    "    total_counter = Counter([item for sublist in indf[grams_d[n_gram]] for item in sublist])\n",
    "    right_counter = Counter(r_grams)\n",
    "    left_counter = Counter(l_grams)\n",
    "\n",
    "    df_all = pd.DataFrame.from_dict(total_counter, orient='index').reset_index()\n",
    "    df_all.columns=['phrase','count']\n",
    "    df_all['count_right']=[right_counter[x] for x in df_all.phrase]\n",
    "    df_all['count_left']=[left_counter[x] for x in df_all.phrase]\n",
    "\n",
    "\n",
    "    df_all['count_left_total']=sum(left_counter.values())\n",
    "    df_all['count_right_total']=sum(right_counter.values())\n",
    "    # frequency of every words except the given one (by row)\n",
    "    #Jensen et al. (2012),p.10 \n",
    "    #f-pck is the frequency of all phrases used in ConÂ­gress c by party k excluding phrase p\n",
    "    df_all['f_right_minus']=( df_all['count_right_total']-df_all['count_right'])/df_all['count_right_total']\n",
    "    df_all['f_left_minus']=( df_all['count_left_total']-df_all['count_left'])/df_all['count_left_total']\n",
    "\n",
    "    df_all['f_right']=df_all['count_right']/df_all['count_right_total']\n",
    "    df_all['f_right_norm'] = (df_all['f_right'] - df_all['f_right'].min()) / (df_all['f_right'].max() - df_all['f_right'].min())  \n",
    "    df_all['f_left']=df_all['count_left']/df_all['count_left_total']\n",
    "    df_all['f_left_norm'] = (df_all['f_left'] - df_all['f_left'].min()) / (df_all['f_left'].max() - df_all['f_left'].min())  \n",
    "\n",
    "    df_all['f_right_minus_norm']=(df_all['f_right_minus'] - df_all['f_right_minus'].min()) / (df_all['f_right_minus'].max() - df_all['f_right_minus'].min()) \n",
    "    df_all['f_left_minus_norm']=(df_all['f_left_minus'] - df_all['f_left_minus'].min()) / (df_all['f_left_minus'].max() - df_all['f_left_minus'].min()) \n",
    "\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def calculate_pearson(df_all):\n",
    "    aa=df_all['f_right_norm']*df_all['f_left_minus_norm'] \n",
    "    bb=df_all['f_left_norm']*df_all['f_right_minus_norm']\n",
    "    cc=aa-bb\n",
    "    dd=cc*cc\n",
    "    d11=df_all['f_right_norm']+df_all['f_left_norm']\n",
    "    d22=df_all['f_right_norm']+df_all['f_right_minus_norm']\n",
    "    d33=df_all['f_left_norm']+df_all['f_left_minus_norm']\n",
    "    d44=df_all['f_right_minus_norm']+df_all['f_left_minus_norm']\n",
    "    denom=d11*d22*d33*d44\n",
    "    pp=dd/denom\n",
    "    return pp\n",
    "\n",
    "def create_phrase_partisanship(df):\n",
    "    aa=df['f_right_norm']+df['f_left_norm']\n",
    "    df['rho']=df['f_right_norm']/aa\n",
    "    \n",
    "    df['gram_partisanship']= 0.5 * df['f_right_norm']*df['rho']+0.5 *df['f_right_norm']*(1-df['rho'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_polarization_correlation(df):\n",
    "    \n",
    "    aa=df['f_left_norm']*-1\n",
    "    bb= df['f_right_norm']*1\n",
    "    df['beta_polarization']=aa+bb\n",
    "\n",
    "    return df\n",
    "\n",
    "def partisanship_by_speach(df_in=df_tok, new_column='partisanship', ngrams_col='tri_grams',partisan_dict=partisan_dict):\n",
    "    df_in[new_column] = [np.empty(0,dtype=float)]*len(df_in)\n",
    "    df_in[new_column] =df_in[new_column].astype(object)\n",
    "    out_res=[]\n",
    "    for n,row in enumerate(df_in[ngrams_col]):\n",
    "    \n",
    "        res=[]\n",
    "        for x in row:\n",
    "            \n",
    "            if x in partisan_dict:\n",
    "                res.append( partisan_dict[x])\n",
    "            \n",
    "            else:\n",
    "                res.append( 0)\n",
    "        out_res.append(res)\n",
    "    df_in[new_column]=out_res\n",
    "    return df_in\n",
    "\n",
    "def create_200r(df_mainf):\n",
    "    indexes_no_applause=[n for n,x in enumerate(df_mainf.phrase) if 'aplausos' not in x]\n",
    "    df_mainf=df_mainf.iloc[indexes_no_applause]\n",
    "\n",
    "    tri_final = df_mainf[0:200].append(df_mainf[-200:], ignore_index=True)\n",
    "    return tri_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe\n",
    "if create_tokenizedDF==True:\n",
    "    df_input = pd.read_pickle('parliament_fdf.pkl')  \n",
    "    df_tok=create_tokenized_dataset(df_input)\n",
    "else:\n",
    "    df_tok = pd.read_pickle('dftok.pkl')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Create n-grams\n",
    "#df_tok=create_grams(df_tok, 2)\n",
    "df_tok=create_grams(df_tok, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 create frequency table\n",
    "df_freq=create_frequency_table_grams(n_gram=3, indf=df_tok, right_parties=right, left_parties=left)\n",
    "# 3 Filter pearson >0\n",
    "df_freq['pearson_quad']=calculate_pearson(df_freq)\n",
    "trigrams_table=df_freq[df_freq.pearson_quad>0]\n",
    "#  4 Add  partisanship by word\n",
    "trigrams_table=create_phrase_partisanship(trigrams_table)\n",
    "trigrams_table=create_polarization_correlation(trigrams_table)\n",
    "trigrams_table=trigrams_table.sort_values(by='gram_partisanship',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Dictionary of trigrams and partisanship\n",
    "partisan_dict=dict(zip(trigrams_table.phrase,trigrams_table.gram_partisanship))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 Partisanship by speach\n",
    "df_tok=partisanship_by_speach(df_in=df_tok, new_column='partisanship', ngrams_col='tri_grams',partisan_dict=partisan_dict)\n",
    "df_tok['avg_partisanship']=df_tok.partisanship.apply(lambda x: sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "      <th>filename</th>\n",
       "      <th>number</th>\n",
       "      <th>session</th>\n",
       "      <th>term</th>\n",
       "      <th>Date</th>\n",
       "      <th>link</th>\n",
       "      <th>party</th>\n",
       "      <th>speaker_ntime</th>\n",
       "      <th>genre</th>\n",
       "      <th>len_speech</th>\n",
       "      <th>year</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_stemer_stop</th>\n",
       "      <th>tokens_cleaned</th>\n",
       "      <th>tri_grams</th>\n",
       "      <th>partisanship</th>\n",
       "      <th>avg_partisanship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>josemanuelpureza</td>\n",
       "      <td>muito bem</td>\n",
       "      <td>darl13sl01n001.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>BE</td>\n",
       "      <td>891.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>[muito, bem]</td>\n",
       "      <td>[muit, bem]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teresalealcoelho</td>\n",
       "      <td>muito bem</td>\n",
       "      <td>darl13sl01n001.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>PSD</td>\n",
       "      <td>87.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>[muito, bem]</td>\n",
       "      <td>[muit, bem]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luismontenegro</td>\n",
       "      <td>muito bom dia a todos sras e srs deputados cum...</td>\n",
       "      <td>darl13sl01n001.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>PSD</td>\n",
       "      <td>694.0</td>\n",
       "      <td>M</td>\n",
       "      <td>204</td>\n",
       "      <td>2015</td>\n",
       "      <td>[muito, bom, dia, a, todos, sras, e, srs, depu...</td>\n",
       "      <td>[muit, bom, dia, tod, sras, srs, deput, cumpr,...</td>\n",
       "      <td>[bom, dia, cumpr, prax, parlament, cabem, lid,...</td>\n",
       "      <td>[bom dia cumpr, dia cumpr prax, cumpr prax par...</td>\n",
       "      <td>[0.00012913223140495868, 0.0001291322314049586...</td>\n",
       "      <td>0.021952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>luismontenegro</td>\n",
       "      <td>o seu exemplo de tolerancia imparcialidade de ...</td>\n",
       "      <td>darl13sl01n001.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>PSD</td>\n",
       "      <td>694.0</td>\n",
       "      <td>M</td>\n",
       "      <td>219</td>\n",
       "      <td>2015</td>\n",
       "      <td>[o, seu, exemplo, de, tolerancia, imparcialida...</td>\n",
       "      <td>[exempl, toleranc, imparcial, competenc, polit...</td>\n",
       "      <td>[exempl, toleranc, imparcial, competenc, polit...</td>\n",
       "      <td>[exempl toleranc imparcial, toleranc imparcial...</td>\n",
       "      <td>[0.00012913223140495868, 0.0001291322314049586...</td>\n",
       "      <td>0.021049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>luismontenegro</td>\n",
       "      <td>sr presidente o grupo parlamentar do psd indic...</td>\n",
       "      <td>darl13sl01n001.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>PSD</td>\n",
       "      <td>694.0</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>2015</td>\n",
       "      <td>[sr, presidente, o, grupo, parlamentar, do, ps...</td>\n",
       "      <td>[sr, president, grup, parlament, psd, indic, s...</td>\n",
       "      <td>[grup, parlament, indic, duart, pachec, exerc,...</td>\n",
       "      <td>[grup parlament indic, parlament indic duart, ...</td>\n",
       "      <td>[0.00012913223140495868, 0.0001291322314049586...</td>\n",
       "      <td>0.001162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            speaker                                             speech  \\\n",
       "0  josemanuelpureza                                         muito bem    \n",
       "1  teresalealcoelho                                         muito bem    \n",
       "2    luismontenegro  muito bom dia a todos sras e srs deputados cum...   \n",
       "3    luismontenegro  o seu exemplo de tolerancia imparcialidade de ...   \n",
       "4    luismontenegro  sr presidente o grupo parlamentar do psd indic...   \n",
       "\n",
       "             filename  number  session  term        Date  \\\n",
       "0  darl13sl01n001.txt       1        1    13  2015-10-23   \n",
       "1  darl13sl01n001.txt       1        1    13  2015-10-23   \n",
       "2  darl13sl01n001.txt       1        1    13  2015-10-23   \n",
       "3  darl13sl01n001.txt       1        1    13  2015-10-23   \n",
       "4  darl13sl01n001.txt       1        1    13  2015-10-23   \n",
       "\n",
       "                                                link party  speaker_ntime  \\\n",
       "0  https://debates.parlamento.pt/catalogo/r3/dar/...    BE          891.0   \n",
       "1  https://debates.parlamento.pt/catalogo/r3/dar/...   PSD           87.0   \n",
       "2  https://debates.parlamento.pt/catalogo/r3/dar/...   PSD          694.0   \n",
       "3  https://debates.parlamento.pt/catalogo/r3/dar/...   PSD          694.0   \n",
       "4  https://debates.parlamento.pt/catalogo/r3/dar/...   PSD          694.0   \n",
       "\n",
       "  genre  len_speech  year                                             tokens  \\\n",
       "0     M           2  2015                                       [muito, bem]   \n",
       "1     F           2  2015                                       [muito, bem]   \n",
       "2     M         204  2015  [muito, bom, dia, a, todos, sras, e, srs, depu...   \n",
       "3     M         219  2015  [o, seu, exemplo, de, tolerancia, imparcialida...   \n",
       "4     M          27  2015  [sr, presidente, o, grupo, parlamentar, do, ps...   \n",
       "\n",
       "                                  tokens_stemer_stop  \\\n",
       "0                                        [muit, bem]   \n",
       "1                                        [muit, bem]   \n",
       "2  [muit, bom, dia, tod, sras, srs, deput, cumpr,...   \n",
       "3  [exempl, toleranc, imparcial, competenc, polit...   \n",
       "4  [sr, president, grup, parlament, psd, indic, s...   \n",
       "\n",
       "                                      tokens_cleaned  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [bom, dia, cumpr, prax, parlament, cabem, lid,...   \n",
       "3  [exempl, toleranc, imparcial, competenc, polit...   \n",
       "4  [grup, parlament, indic, duart, pachec, exerc,...   \n",
       "\n",
       "                                           tri_grams  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [bom dia cumpr, dia cumpr prax, cumpr prax par...   \n",
       "3  [exempl toleranc imparcial, toleranc imparcial...   \n",
       "4  [grup parlament indic, parlament indic duart, ...   \n",
       "\n",
       "                                        partisanship  avg_partisanship  \n",
       "0                                                 []          0.000000  \n",
       "1                                                 []          0.000000  \n",
       "2  [0.00012913223140495868, 0.0001291322314049586...          0.021952  \n",
       "3  [0.00012913223140495868, 0.0001291322314049586...          0.021049  \n",
       "4  [0.00012913223140495868, 0.0001291322314049586...          0.001162  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tok.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddb3f830e79c6f8e791b80246b7047706826e249abf27510d15251ed3cae5420"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
