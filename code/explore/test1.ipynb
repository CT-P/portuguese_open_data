{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import validators\n",
    "import datetime\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downloads\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('rslp')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "characters_for_name=60\n",
    "legislature='dar/01'\n",
    "cycle='14'\n",
    "\n",
    "stop_words_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "#stop_words = [\"the\",\"it\",\"she\",\"he\", \"a\"] #Uncomment this line if you want to use your own list of stopwords.\n",
    "#The stemmers and lemmers need to be initialized before bing run\n",
    "#porter = nltk.stem.porter.PorterStemmer()\n",
    "snowball = nltk.stem.snowball.SnowballStemmer('portuguese')\n",
    "#wordnet = nltk.stem.WordNetLemmatizer()\n",
    "#RSLP=nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "def add_zeros(int_):\n",
    "    if len(str(int_))<2:\n",
    "        return '00'+str(int_)\n",
    "    if len(str(int_))<3:\n",
    "        return '0'+str(int_)\n",
    "    if len(str(int_))==3:\n",
    "        return str(int_)\n",
    "\n",
    "def get_text_from_html(url__):\n",
    "    from bs4 import BeautifulSoup\n",
    "    res = requests.get(url__)\n",
    "    html_page = res.content\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "    return str(soup.noscript)\n",
    "\n",
    "def read_input_table(current_directory=\"C:\\\\Users\\caperei\",cycle='14',session='1' ):\n",
    "\n",
    "    data_directory=f\"\\portuguese_open_data\\data\\cycle\\{cycle}\\session\\{session}\\\\numbers_dates_pages.csv\"\n",
    "    input_data=pd.read_csv(r\"C:\\Users\\caperei\\portuguese_open_data\\data\\cyle\\14\\session\\1\\numbers_dates_pages.csv\")\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex\n",
    "def check_dialog(text_):\n",
    "    pat=\"(?:</p><p>.*?\\(.*?\\): —)\"\n",
    "    match=re.findall(pat, text_)\n",
    "    if match is None :\n",
    "        return 'no_dialog'\n",
    "    else:\n",
    "        for m in match:\n",
    "            \n",
    "            return m\n",
    "\n",
    "def extract_dialog(full_text,characters_for_name):    \n",
    "    if full_text is None:\n",
    "        return None\n",
    "    else:\n",
    "        dialogs=[(m.start(0), m.end(0)) for m in re.finditer('</p><p></p><p>(.+?): —', full_text)]\n",
    "        out=[]\n",
    "        if len(dialogs)==1:\n",
    "            out.append(full_text[dialogs[0][1]-characters_for_name:])\n",
    "        if len(dialogs)>1:\n",
    "            for i in range(0, len(dialogs)-1):\n",
    "                out.append(full_text[dialogs[i][1]-characters_for_name:dialogs[i+1][0]])\n",
    "            out.append(full_text[dialogs[len(dialogs)-1][1]-50:])\n",
    "        return out\n",
    "\n",
    "    \n",
    "def extract_party_name(dialogs):\n",
    "    if dialogs is None:\n",
    "        return None\n",
    "    else:\n",
    "        res=[]\n",
    "        for i in dialogs:\n",
    "                    positions=[(m.start(0), m.end(0)) for m in re.finditer('\\((.+?)\\): —', i)]\n",
    "                    if len(positions)==0:\n",
    "                        res.append(['No','No'])\n",
    "                    else:\n",
    "                        party=re.findall('\\((.+?)\\)',i)\n",
    "                        name_aux=i[positions[0][1]-50:positions[0][1]]\n",
    "                        name=re.sub(r'\\b\\w{1,2}\\b', '', name_aux).replace('.','').replace ('()','').replace('  ','').replace('<','').replace('>','').replace('/','').replace(': —','')\n",
    "                        if len(party)>0:\n",
    "                            party=party[0]\n",
    "                        res.append([party,name])\n",
    "        return res\n",
    "\n",
    "def add_speech_next_page(df):\n",
    "    for pi in range(1,df.page.max()+1):\n",
    "        if len(df[df.page==pi].speech.values[0])>0:\n",
    "            speeches=df[df.page==pi].speech.values[0]\n",
    "            if '</noscript>' in speeches[-1]:\n",
    "                \n",
    "                for n in range(1,df.page.max()-pi):\n",
    "                    if ': —' in df[df.page==pi+n].text_1.values[0]:\n",
    "                        \n",
    "                        in_=df[df.page==pi+n].text_1.values[0].find(': —')\n",
    "                        df[df.page==pi].speech.values[0][-1]=df[df.page==pi].speech.values[0][-1]+' '+str(df[df.page==pi+n].text_1.values[0][0:in_])\n",
    "                        \n",
    "                        break\n",
    "                    else:\n",
    "                        \n",
    "                        df[df.page==pi].speech.values[0][-1]=df[df.page==pi].speech.values[0][-1]+' '+str(df[df.page==pi+n].text_1.values[0])\n",
    "    return df\n",
    "\n",
    "\n",
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "  if(type(text)==float):\n",
    "    return text\n",
    "  ans=\"\"  \n",
    "  for i in text:     \n",
    "    if i not in string.punctuation+'<p></p>ºª':\n",
    "      ans+=i    \n",
    "  return ans\n",
    "\n",
    "def normlizeTokens(tokenLst, stopwordLst = None, stemmer = None):\n",
    "    #We can use a generator here as we just need to iterate over it\n",
    "\n",
    "    #Lowering the case and removing non-words\n",
    "    workingIter = (w.lower() for w in tokenLst if w.isalpha())\n",
    "\n",
    "    #Now we can use the semmer, if provided\n",
    "    if stemmer is not None:\n",
    "        workingIter = (stemmer.stem(w) for w in workingIter)\n",
    "         \n",
    "    #And remove the stopwords\n",
    "    if stopwordLst is not None:\n",
    "        workingIter = (w for w in workingIter if w not in stopwordLst)\n",
    "    #We will return a list with the stopwords removed\n",
    "    return list(workingIter)\n",
    "\n",
    "def generate_N_grams(text,ngram=1):\n",
    "  words=[word for word in text]  \n",
    "  temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "  ans=[' '.join(ngram) for ngram in temp]\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions scrapping\n",
    "def build_transcripts_table_from_html(session=['01'],legislature='dar/01', cycle='14'):\n",
    "    df = pd.DataFrame(columns=['legislature','cycle','session','number','date','page', 'text_1','url'])        \n",
    "    #session=['01'] #['01','02','03']\n",
    "    numbers_dates=list(zip(input_data.number, input_data.date,input_data.pages )) #[0:1]\n",
    "    pages=input_data.pages.values #[0:1]\n",
    "    s_c=[]\n",
    "    n_c=[]\n",
    "    d_c=[]\n",
    "    p_c=[]\n",
    "    u_c=[]\n",
    "    t_c=[]\n",
    "    for s in session:\n",
    "        for number, date, page in numbers_dates:\n",
    "            number=add_zeros(number)\n",
    "            date=datetime.datetime.strptime(date, '%d/%m/%Y').strftime('%Y-%m-%d')\n",
    "            for page_i in range(1,page+1):\n",
    "                    url_=f'https://debates.parlamento.pt/catalogo/r3/{legislature}/{cycle}/{s}/{number}/{date}/{page_i}'\n",
    "                    if validators.url(url_):\n",
    "                        #print (url_)\n",
    "                        u_c.append(url_)\n",
    "                        p_c.append(page_i)\n",
    "                        t_c.append(get_text_from_html(url_))\n",
    "                        s_c.append(s)\n",
    "                        n_c.append(number)\n",
    "                        d_c.append(date)\n",
    "    df['page']=p_c\n",
    "    df['session']=s_c\n",
    "    df['number']=n_c\n",
    "    df['date']=d_c\n",
    "\n",
    "    df['text_1']=t_c\n",
    "    df['url']=u_c\n",
    "    df['legislature']=legislature\n",
    "    df['cycle']=cycle    \n",
    "    return df\n",
    "\n",
    "def add_party_speaker(df,characters_for_name ):\n",
    "    #add columns\n",
    "    df['speech']=[extract_dialog(t,characters_for_name) for t in df.text_1 ]\n",
    "    df['party']=[extract_party_name(t) for t in df.speech ]\n",
    "    df=add_speech_next_page(df)\n",
    "    #re arrange by speaker and party\n",
    "    df1=df.explode(['speech', 'party']).reset_index(drop=True)\n",
    "    df2=df1.dropna(subset=['party'])\n",
    "    df2['party_s']=[t[0] for t in df2.party]\n",
    "    df2['speaker']=[t[1] for t in df2.party]\n",
    "    df2=df2[df2.party_s!='No']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>date</th>\n",
       "      <th>pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25/10/2019</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>30/10/2019</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>31/10/2019</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number        date  pages\n",
       "0       1  25/10/2019     13\n",
       "1       2  30/10/2019    124\n",
       "2       3  31/10/2019     26"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data=read_input_table()\n",
    "input_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=build_transcripts_table_from_html()\n",
    "#df.to_pickle('portuguese_transcripts_s1.pkl') \n",
    "df = pd.read_pickle('portuguese_transcripts_s1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legislature</th>\n",
       "      <th>cycle</th>\n",
       "      <th>session</th>\n",
       "      <th>number</th>\n",
       "      <th>date</th>\n",
       "      <th>page</th>\n",
       "      <th>text_1</th>\n",
       "      <th>url</th>\n",
       "      <th>speech</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;Sábado, 26 de outubro de 2019  ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[es.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;A Sr.ª Ana Catarina Mendonça...</td>\n",
       "      <td>[[PS, Ana Catarina Mendonça Mendes ], [No, No]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;26 DE OUTUBRO DE 2019 &lt;/p&gt;&lt;p&gt;3 ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[er votado, Sr. Presidente. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr...</td>\n",
       "      <td>[[No, No], [PS,  Pedro Delgado Alves ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;26 DE OUTUBRO DE 2019 &lt;/p&gt;&lt;p&gt;5 ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[residente, muito obrigado. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr...</td>\n",
       "      <td>[[No, No]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  legislature cycle session number        date  page  \\\n",
       "0      dar/01    14      01    001  2019-10-25     1   \n",
       "1      dar/01    14      01    001  2019-10-25     2   \n",
       "2      dar/01    14      01    001  2019-10-25     3   \n",
       "3      dar/01    14      01    001  2019-10-25     4   \n",
       "4      dar/01    14      01    001  2019-10-25     5   \n",
       "\n",
       "                                              text_1  \\\n",
       "0  <noscript>\\n<p>Sábado, 26 de outubro de 2019  ...   \n",
       "1  <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "2  <noscript>\\n<p>26 DE OUTUBRO DE 2019 </p><p>3 ...   \n",
       "3  <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "4  <noscript>\\n<p>26 DE OUTUBRO DE 2019 </p><p>5 ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "1  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "2  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "3  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "4  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "\n",
       "                                              speech  \\\n",
       "0                                                 []   \n",
       "1  [es.</p><p></p><p>A Sr.ª Ana Catarina Mendonça...   \n",
       "2  [er votado, Sr. Presidente. </p><p></p><p>O Sr...   \n",
       "3                                                 []   \n",
       "4  [residente, muito obrigado. </p><p></p><p>O Sr...   \n",
       "\n",
       "                                               party  \n",
       "0                                                 []  \n",
       "1  [[PS, Ana Catarina Mendonça Mendes ], [No, No]...  \n",
       "2            [[No, No], [PS,  Pedro Delgado Alves ]]  \n",
       "3                                                 []  \n",
       "4                                         [[No, No]]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d76f48c138f4>:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['party_s']=[t[0] for t in df2.party]\n",
      "<ipython-input-6-d76f48c138f4>:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['speaker']=[t[1] for t in df2.party]\n"
     ]
    }
   ],
   "source": [
    "df2=add_party_speaker(df,characters_for_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['speech1']= df2['speech'].apply(lambda x:remove_punctuation(x))\n",
    "df2['tokenized_text'] = df2['speech1'].apply(lambda x: nltk.word_tokenize(x))\n",
    "df2['normalized_tokens'] = df2['tokenized_text'].apply(lambda x: normlizeTokens(x, stopwordLst = stop_words_nltk, stemmer = snowball))\n",
    "df2['normalized_tokens_count'] = df2['normalized_tokens'].apply(lambda x: len(x))\n",
    "df2['uni_grams'] = df2['normalized_tokens'].apply(lambda x: generate_N_grams(x,1))\n",
    "df2['bi_grams'] = df2['normalized_tokens'].apply(lambda x: generate_N_grams(x,2))\n",
    "df2['tri_grams'] = df2['normalized_tokens'].apply(lambda x: generate_N_grams(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legislature</th>\n",
       "      <th>cycle</th>\n",
       "      <th>session</th>\n",
       "      <th>number</th>\n",
       "      <th>date</th>\n",
       "      <th>page</th>\n",
       "      <th>text_1</th>\n",
       "      <th>url</th>\n",
       "      <th>speech</th>\n",
       "      <th>party</th>\n",
       "      <th>speech1</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>normalized_tokens</th>\n",
       "      <th>normalized_tokens_count</th>\n",
       "      <th>uni_grams</th>\n",
       "      <th>bi_grams</th>\n",
       "      <th>tri_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;Sábado, 26 de outubro de 2019  ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[es.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;A Sr.ª Ana Catarina Mendonça...</td>\n",
       "      <td>[[PS, Ana Catarina Mendonça Mendes ], [No, No]...</td>\n",
       "      <td>es.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;A Sr.ª Ana Catarina Mendonça ...</td>\n",
       "      <td>[es., &lt;, /p, &gt;, &lt;, p, &gt;, &lt;, /p, &gt;, &lt;, p, &gt;, A,...</td>\n",
       "      <td>[p, p, ana, catarin, mendonc, mend, ps, srs, d...</td>\n",
       "      <td>412</td>\n",
       "      <td>[p, p, ana, catarin, mendonc, mend, ps, srs, d...</td>\n",
       "      <td>[p p, p ana, ana catarin, catarin mendonc, men...</td>\n",
       "      <td>[p p ana, p ana catarin, ana catarin mendonc, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;26 DE OUTUBRO DE 2019 &lt;/p&gt;&lt;p&gt;3 ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[er votado, Sr. Presidente. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr...</td>\n",
       "      <td>[[No, No], [PS,  Pedro Delgado Alves ]]</td>\n",
       "      <td>er votado, Sr. Presidente. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr....</td>\n",
       "      <td>[er, votado, ,, Sr., Presidente, ., &lt;, /p, &gt;, ...</td>\n",
       "      <td>[er, vot, president, p, p, president, muit, ob...</td>\n",
       "      <td>755</td>\n",
       "      <td>[er, vot, president, p, p, president, muit, ob...</td>\n",
       "      <td>[er vot, vot president, president p, p p, p pr...</td>\n",
       "      <td>[er vot president, vot president p, president ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;26 DE OUTUBRO DE 2019 &lt;/p&gt;&lt;p&gt;5 ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[residente, muito obrigado. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr...</td>\n",
       "      <td>[[No, No]]</td>\n",
       "      <td>residente, muito obrigado. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr....</td>\n",
       "      <td>[residente, ,, muito, obrigado, ., &lt;, /p, &gt;, &lt;...</td>\n",
       "      <td>[resident, muit, obrig, p, p, president, muit,...</td>\n",
       "      <td>273</td>\n",
       "      <td>[resident, muit, obrig, p, p, president, muit,...</td>\n",
       "      <td>[resident muit, muit obrig, obrig p, p p, p pr...</td>\n",
       "      <td>[resident muit obrig, muit obrig p, obrig p p,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  legislature cycle session number        date  page  \\\n",
       "0      dar/01    14      01    001  2019-10-25     1   \n",
       "1      dar/01    14      01    001  2019-10-25     2   \n",
       "2      dar/01    14      01    001  2019-10-25     3   \n",
       "3      dar/01    14      01    001  2019-10-25     4   \n",
       "4      dar/01    14      01    001  2019-10-25     5   \n",
       "\n",
       "                                              text_1  \\\n",
       "0  <noscript>\\n<p>Sábado, 26 de outubro de 2019  ...   \n",
       "1  <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "2  <noscript>\\n<p>26 DE OUTUBRO DE 2019 </p><p>3 ...   \n",
       "3  <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "4  <noscript>\\n<p>26 DE OUTUBRO DE 2019 </p><p>5 ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "1  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "2  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "3  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "4  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "\n",
       "                                              speech  \\\n",
       "0                                                 []   \n",
       "1  [es.</p><p></p><p>A Sr.ª Ana Catarina Mendonça...   \n",
       "2  [er votado, Sr. Presidente. </p><p></p><p>O Sr...   \n",
       "3                                                 []   \n",
       "4  [residente, muito obrigado. </p><p></p><p>O Sr...   \n",
       "\n",
       "                                               party  \\\n",
       "0                                                 []   \n",
       "1  [[PS, Ana Catarina Mendonça Mendes ], [No, No]...   \n",
       "2            [[No, No], [PS,  Pedro Delgado Alves ]]   \n",
       "3                                                 []   \n",
       "4                                         [[No, No]]   \n",
       "\n",
       "                                             speech1  \\\n",
       "0                                                      \n",
       "1  es.</p><p></p><p>A Sr.ª Ana Catarina Mendonça ...   \n",
       "2  er votado, Sr. Presidente. </p><p></p><p>O Sr....   \n",
       "3                                                      \n",
       "4  residente, muito obrigado. </p><p></p><p>O Sr....   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0                                                 []   \n",
       "1  [es., <, /p, >, <, p, >, <, /p, >, <, p, >, A,...   \n",
       "2  [er, votado, ,, Sr., Presidente, ., <, /p, >, ...   \n",
       "3                                                 []   \n",
       "4  [residente, ,, muito, obrigado, ., <, /p, >, <...   \n",
       "\n",
       "                                   normalized_tokens  normalized_tokens_count  \\\n",
       "0                                                 []                        0   \n",
       "1  [p, p, ana, catarin, mendonc, mend, ps, srs, d...                      412   \n",
       "2  [er, vot, president, p, p, president, muit, ob...                      755   \n",
       "3                                                 []                        0   \n",
       "4  [resident, muit, obrig, p, p, president, muit,...                      273   \n",
       "\n",
       "                                           uni_grams  \\\n",
       "0                                                 []   \n",
       "1  [p, p, ana, catarin, mendonc, mend, ps, srs, d...   \n",
       "2  [er, vot, president, p, p, president, muit, ob...   \n",
       "3                                                 []   \n",
       "4  [resident, muit, obrig, p, p, president, muit,...   \n",
       "\n",
       "                                            bi_grams  \\\n",
       "0                                                 []   \n",
       "1  [p p, p ana, ana catarin, catarin mendonc, men...   \n",
       "2  [er vot, vot president, president p, p p, p pr...   \n",
       "3                                                 []   \n",
       "4  [resident muit, muit obrig, obrig p, p p, p pr...   \n",
       "\n",
       "                                           tri_grams  \n",
       "0                                                 []  \n",
       "1  [p p ana, p ana catarin, ana catarin mendonc, ...  \n",
       "2  [er vot president, vot president p, president ...  \n",
       "3                                                 []  \n",
       "4  [resident muit obrig, muit obrig p, obrig p p,...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a5ab6f8988138c4aafa838927270364e946a56a2b152cd75ab864ac6056d77"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
