{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import validators\n",
    "import datetime\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downloads\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('rslp')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "characters_for_name=60\n",
    "legislature='dar/01'\n",
    "cycle='14'\n",
    "\n",
    "stop_words_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "#stop_words = [\"the\",\"it\",\"she\",\"he\", \"a\"] #Uncomment this line if you want to use your own list of stopwords.\n",
    "#The stemmers and lemmers need to be initialized before bing run\n",
    "#porter = nltk.stem.porter.PorterStemmer()\n",
    "snowball = nltk.stem.snowball.SnowballStemmer('portuguese')\n",
    "#wordnet = nltk.stem.WordNetLemmatizer()\n",
    "#RSLP=nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "def add_zeros(int_):\n",
    "    if len(str(int_))<2:\n",
    "        return '00'+str(int_)\n",
    "    if len(str(int_))<3:\n",
    "        return '0'+str(int_)\n",
    "    if len(str(int_))==3:\n",
    "        return str(int_)\n",
    "\n",
    "def get_text_from_html(url__):\n",
    "    from bs4 import BeautifulSoup\n",
    "    res = requests.get(url__)\n",
    "    html_page = res.content\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "    return str(soup.noscript)\n",
    "\n",
    "def read_input_table(current_directory=\"C:\\\\Users\\caperei\",cycle='14',session='1' ):\n",
    "\n",
    "    data_directory=f\"\\portuguese_open_data\\data\\cycle\\{cycle}\\session\\{session}\\\\numbers_dates_pages.csv\"\n",
    "    input_data=pd.read_csv(r\"C:\\Users\\caperei\\portuguese_open_data\\data\\cyle\\14\\session\\1\\numbers_dates_pages.csv\")\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex\n",
    "def check_dialog(text_):\n",
    "    pat=\"(?:</p><p>.*?\\(.*?\\): —)\"\n",
    "    match=re.findall(pat, text_)\n",
    "    if match is None :\n",
    "        return 'no_dialog'\n",
    "    else:\n",
    "        for m in match:\n",
    "            \n",
    "            return m\n",
    "\n",
    "def extract_dialog(full_text,characters_for_name):    \n",
    "    if full_text is None:\n",
    "        return None\n",
    "    else:\n",
    "        dialogs=[(m.start(0), m.end(0)) for m in re.finditer('</p><p></p><p>(.+?): —', full_text)]\n",
    "        out=[]\n",
    "        if len(dialogs)==1:\n",
    "            out.append(full_text[dialogs[0][1]-characters_for_name:])\n",
    "        if len(dialogs)>1:\n",
    "            for i in range(0, len(dialogs)-1):\n",
    "                out.append(full_text[dialogs[i][1]-characters_for_name:dialogs[i+1][0]])\n",
    "            out.append(full_text[dialogs[len(dialogs)-1][1]-50:])\n",
    "        return out\n",
    "\n",
    "    \n",
    "def extract_party_name(dialogs):\n",
    "    if dialogs is None:\n",
    "        return None\n",
    "    else:\n",
    "        res=[]\n",
    "        for i in dialogs:\n",
    "                    positions=[(m.start(0), m.end(0)) for m in re.finditer('\\((.+?)\\): —', i)]\n",
    "                    if len(positions)==0:\n",
    "                        res.append(['No','No'])\n",
    "                    else:\n",
    "                        party=re.findall('\\((.+?)\\)',i)\n",
    "                        name_aux=i[positions[0][1]-50:positions[0][1]]\n",
    "                        name=re.sub(r'\\b\\w{1,2}\\b', '', name_aux).replace('.','').replace ('()','').replace('  ','').replace('<','').replace('>','').replace('/','').replace(': —','')\n",
    "                        if len(party)>0:\n",
    "                            party=party[0]\n",
    "                        res.append([party,name])\n",
    "        return res\n",
    "\n",
    "def add_speech_next_page(df):\n",
    "    for pi in range(1,df.page.max()+1):\n",
    "        if len(df[df.page==pi].speech.values[0])>0:\n",
    "            speeches=df[df.page==pi].speech.values[0]\n",
    "            if '</noscript>' in speeches[-1]:\n",
    "                \n",
    "                for n in range(1,df.page.max()-pi):\n",
    "                    if ': —' in df[df.page==pi+n].text_1.values[0]:\n",
    "                        \n",
    "                        in_=df[df.page==pi+n].text_1.values[0].find(': —')\n",
    "                        df[df.page==pi].speech.values[0][-1]=df[df.page==pi].speech.values[0][-1]+' '+str(df[df.page==pi+n].text_1.values[0][0:in_])\n",
    "                        \n",
    "                        break\n",
    "                    else:\n",
    "                        \n",
    "                        df[df.page==pi].speech.values[0][-1]=df[df.page==pi].speech.values[0][-1]+' '+str(df[df.page==pi+n].text_1.values[0])\n",
    "    return df\n",
    "\n",
    "\n",
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "  if(type(text)==float):\n",
    "    return text\n",
    "  ans=\"\"  \n",
    "  for i in text:     \n",
    "    if i not in string.punctuation+'<p></p>ºª':\n",
    "      ans+=i    \n",
    "  return ans\n",
    "\n",
    "def normlizeTokens(tokenLst, stopwordLst = None, stemmer = None):\n",
    "    #We can use a generator here as we just need to iterate over it\n",
    "\n",
    "    #Lowering the case and removing non-words\n",
    "    workingIter = (w.lower() for w in tokenLst if w.isalpha())\n",
    "\n",
    "    #Now we can use the semmer, if provided\n",
    "    if stemmer is not None:\n",
    "        workingIter = (stemmer.stem(w) for w in workingIter)\n",
    "         \n",
    "    #And remove the stopwords\n",
    "    if stopwordLst is not None:\n",
    "        workingIter = (w for w in workingIter if w not in stopwordLst)\n",
    "    #We will return a list with the stopwords removed\n",
    "    return list(workingIter)\n",
    "\n",
    "def generate_N_grams(text,ngram=1):\n",
    "  words=[word for word in text]  \n",
    "  temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "  ans=[' '.join(ngram) for ngram in temp]\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions scrapping\n",
    "def build_transcripts_table_from_html(session=['01'],legislature='dar/01', cycle='14'):\n",
    "    df = pd.DataFrame(columns=['legislature','cycle','session','number','date','page', 'text_1','url'])        \n",
    "    #session=['01'] #['01','02','03']\n",
    "    numbers_dates=list(zip(input_data.number, input_data.date,input_data.pages )) #[0:1]\n",
    "    pages=input_data.pages.values #[0:1]\n",
    "    s_c=[]\n",
    "    n_c=[]\n",
    "    d_c=[]\n",
    "    p_c=[]\n",
    "    u_c=[]\n",
    "    t_c=[]\n",
    "    for s in session:\n",
    "        for number, date, page in numbers_dates:\n",
    "            number=add_zeros(number)\n",
    "            date=datetime.datetime.strptime(date, '%d/%m/%Y').strftime('%Y-%m-%d')\n",
    "            for page_i in range(1,page+1):\n",
    "                    url_=f'https://debates.parlamento.pt/catalogo/r3/{legislature}/{cycle}/{s}/{number}/{date}/{page_i}'\n",
    "                    if validators.url(url_):\n",
    "                        #print (url_)\n",
    "                        u_c.append(url_)\n",
    "                        p_c.append(page_i)\n",
    "                        t_c.append(get_text_from_html(url_))\n",
    "                        s_c.append(s)\n",
    "                        n_c.append(number)\n",
    "                        d_c.append(date)\n",
    "    df['page']=p_c\n",
    "    df['session']=s_c\n",
    "    df['number']=n_c\n",
    "    df['date']=d_c\n",
    "\n",
    "    df['text_1']=t_c\n",
    "    df['url']=u_c\n",
    "    df['legislature']=legislature\n",
    "    df['cycle']=cycle    \n",
    "    return df\n",
    "\n",
    "def add_party_speaker(df,characters_for_name ):\n",
    "    #add columns\n",
    "    df['speech']=[extract_dialog(t,characters_for_name) for t in df.text_1 ]\n",
    "    df['party']=[extract_party_name(t) for t in df.speech ]\n",
    "    df=add_speech_next_page(df)\n",
    "    #re arrange by speaker and party\n",
    "    df1=df.explode(['speech', 'party']).reset_index(drop=True)\n",
    "    df2=df1.dropna(subset=['party'])\n",
    "    df2['party_s']=[t[0] for t in df2.party]\n",
    "    df2['speaker']=[t[1] for t in df2.party]\n",
    "    df2=df2[df2.party_s!='No']\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>date</th>\n",
       "      <th>pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25/10/2019</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>30/10/2019</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>31/10/2019</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number        date  pages\n",
       "0       1  25/10/2019     13\n",
       "1       2  30/10/2019    124\n",
       "2       3  31/10/2019     26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data=read_input_table()\n",
    "input_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=build_transcripts_table_from_html()\n",
    "#df.to_pickle('portuguese_transcripts_s1.pkl') \n",
    "df = pd.read_pickle('portuguese_transcripts_s1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legislature</th>\n",
       "      <th>cycle</th>\n",
       "      <th>session</th>\n",
       "      <th>number</th>\n",
       "      <th>date</th>\n",
       "      <th>page</th>\n",
       "      <th>text_1</th>\n",
       "      <th>url</th>\n",
       "      <th>speech</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;Sábado, 26 de outubro de 2019  ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[es.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;A Sr.ª Ana Catarina Mendonça...</td>\n",
       "      <td>[[PS, Ana Catarina Mendonça Mendes ], [No, No]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;26 DE OUTUBRO DE 2019 &lt;/p&gt;&lt;p&gt;3 ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[er votado, Sr. Presidente. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr...</td>\n",
       "      <td>[[No, No], [PS,  Pedro Delgado Alves ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;26 DE OUTUBRO DE 2019 &lt;/p&gt;&lt;p&gt;5 ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[residente, muito obrigado. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr...</td>\n",
       "      <td>[[No, No]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  legislature cycle session number        date  page  \\\n",
       "0      dar/01    14      01    001  2019-10-25     1   \n",
       "1      dar/01    14      01    001  2019-10-25     2   \n",
       "2      dar/01    14      01    001  2019-10-25     3   \n",
       "3      dar/01    14      01    001  2019-10-25     4   \n",
       "4      dar/01    14      01    001  2019-10-25     5   \n",
       "\n",
       "                                              text_1  \\\n",
       "0  <noscript>\\n<p>Sábado, 26 de outubro de 2019  ...   \n",
       "1  <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "2  <noscript>\\n<p>26 DE OUTUBRO DE 2019 </p><p>3 ...   \n",
       "3  <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "4  <noscript>\\n<p>26 DE OUTUBRO DE 2019 </p><p>5 ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "1  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "2  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "3  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "4  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "\n",
       "                                              speech  \\\n",
       "0                                                 []   \n",
       "1  [es.</p><p></p><p>A Sr.ª Ana Catarina Mendonça...   \n",
       "2  [er votado, Sr. Presidente. </p><p></p><p>O Sr...   \n",
       "3                                                 []   \n",
       "4  [residente, muito obrigado. </p><p></p><p>O Sr...   \n",
       "\n",
       "                                               party  \n",
       "0                                                 []  \n",
       "1  [[PS, Ana Catarina Mendonça Mendes ], [No, No]...  \n",
       "2            [[No, No], [PS,  Pedro Delgado Alves ]]  \n",
       "3                                                 []  \n",
       "4                                         [[No, No]]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-99982d4d3f5c>:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['party_s']=[t[0] for t in df2.party]\n",
      "<ipython-input-18-99982d4d3f5c>:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['speaker']=[t[1] for t in df2.party]\n"
     ]
    }
   ],
   "source": [
    "df2=add_party_speaker(df,characters_for_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['speech1']= df2['speech'].apply(lambda x:remove_punctuation(x))\n",
    "df2['tokenized_text'] = df2['speech1'].apply(lambda x: nltk.word_tokenize(x))\n",
    "df2['normalized_tokens'] = df2['tokenized_text'].apply(lambda x: normlizeTokens(x, stopwordLst = stop_words_nltk, stemmer = snowball))\n",
    "df2['normalized_tokens_count'] = df2['normalized_tokens'].apply(lambda x: len(x))\n",
    "df2['uni_grams'] = df2['normalized_tokens'].apply(lambda x: generate_N_grams(x,1))\n",
    "df2['bi_grams'] = df2['normalized_tokens'].apply(lambda x: generate_N_grams(x,2))\n",
    "df2['tri_grams'] = df2['normalized_tokens'].apply(lambda x: generate_N_grams(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.party_s.unique()\n",
    "parties=['PS', 'PSD', 'BE', 'PCP', 'CDS-PP', 'PAN', 'PEV','CH','IL','L','CDS','PCP']\n",
    "df3=df2[df2.party_s.isin(parties)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legislature</th>\n",
       "      <th>cycle</th>\n",
       "      <th>session</th>\n",
       "      <th>number</th>\n",
       "      <th>date</th>\n",
       "      <th>page</th>\n",
       "      <th>text_1</th>\n",
       "      <th>url</th>\n",
       "      <th>speech</th>\n",
       "      <th>party</th>\n",
       "      <th>speech1</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>normalized_tokens</th>\n",
       "      <th>normalized_tokens_count</th>\n",
       "      <th>uni_grams</th>\n",
       "      <th>bi_grams</th>\n",
       "      <th>tri_grams</th>\n",
       "      <th>party_s</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>es.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;A Sr.ª Ana Catarina Mendonça ...</td>\n",
       "      <td>[PS, Ana Catarina Mendonça Mendes ]</td>\n",
       "      <td>esA Sr Ana Catarina Mendonça Mendes PS — Sras ...</td>\n",
       "      <td>[esA, Sr, Ana, Catarina, Mendonça, Mendes, PS,...</td>\n",
       "      <td>[esa, sr, ana, catarin, mendonc, mend, ps, sra...</td>\n",
       "      <td>90</td>\n",
       "      <td>[esa, sr, ana, catarin, mendonc, mend, ps, sra...</td>\n",
       "      <td>[esa sr, sr ana, ana catarin, catarin mendonc,...</td>\n",
       "      <td>[esa sr ana, sr ana catarin, ana catarin mendo...</td>\n",
       "      <td>PS</td>\n",
       "      <td>Ana Catarina Mendonça Mendes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;26 DE OUTUBRO DE 2019 &lt;/p&gt;&lt;p&gt;3 ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>o. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr. Pedro Delgado Alves (PS...</td>\n",
       "      <td>[PS,  Pedro Delgado Alves ]</td>\n",
       "      <td>o O Sr Pedro Delgado Alves PS — Sr Presidente ...</td>\n",
       "      <td>[o, O, Sr, Pedro, Delgado, Alves, PS, —, Sr, P...</td>\n",
       "      <td>[sr, pedr, delg, alves, ps, sr, president, sra...</td>\n",
       "      <td>682</td>\n",
       "      <td>[sr, pedr, delg, alves, ps, sr, president, sra...</td>\n",
       "      <td>[sr pedr, pedr delg, delg alves, alves ps, ps ...</td>\n",
       "      <td>[sr pedr delg, pedr delg alves, delg alves ps,...</td>\n",
       "      <td>PS</td>\n",
       "      <td>Pedro Delgado Alves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>&lt;/p&gt;&lt;p&gt;A Sr.ª Ana Catarina Mendonça Mendes (PS...</td>\n",
       "      <td>[PS, Ana Catarina Mendonça Mendes ]</td>\n",
       "      <td>A Sr Ana Catarina Mendonça Mendes PS — Sr Pres...</td>\n",
       "      <td>[A, Sr, Ana, Catarina, Mendonça, Mendes, PS, —...</td>\n",
       "      <td>[sr, ana, catarin, mendonc, mend, ps, sr, pres...</td>\n",
       "      <td>271</td>\n",
       "      <td>[sr, ana, catarin, mendonc, mend, ps, sr, pres...</td>\n",
       "      <td>[sr ana, ana catarin, catarin mendonc, mendonc...</td>\n",
       "      <td>[sr ana catarin, ana catarin mendonc, catarin ...</td>\n",
       "      <td>PS</td>\n",
       "      <td>Ana Catarina Mendonça Mendes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   legislature cycle session number        date  page  \\\n",
       "1       dar/01    14      01    001  2019-10-25     2   \n",
       "5       dar/01    14      01    001  2019-10-25     3   \n",
       "12      dar/01    14      01    001  2019-10-25     8   \n",
       "\n",
       "                                               text_1  \\\n",
       "1   <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "5   <noscript>\\n<p>26 DE OUTUBRO DE 2019 </p><p>3 ...   \n",
       "12  <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "\n",
       "                                                  url  \\\n",
       "1   https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "5   https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "12  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "\n",
       "                                               speech  \\\n",
       "1   es.</p><p></p><p>A Sr.ª Ana Catarina Mendonça ...   \n",
       "5   o. </p><p></p><p>O Sr. Pedro Delgado Alves (PS...   \n",
       "12  </p><p>A Sr.ª Ana Catarina Mendonça Mendes (PS...   \n",
       "\n",
       "                                  party  \\\n",
       "1   [PS, Ana Catarina Mendonça Mendes ]   \n",
       "5           [PS,  Pedro Delgado Alves ]   \n",
       "12  [PS, Ana Catarina Mendonça Mendes ]   \n",
       "\n",
       "                                              speech1  \\\n",
       "1   esA Sr Ana Catarina Mendonça Mendes PS — Sras ...   \n",
       "5   o O Sr Pedro Delgado Alves PS — Sr Presidente ...   \n",
       "12  A Sr Ana Catarina Mendonça Mendes PS — Sr Pres...   \n",
       "\n",
       "                                       tokenized_text  \\\n",
       "1   [esA, Sr, Ana, Catarina, Mendonça, Mendes, PS,...   \n",
       "5   [o, O, Sr, Pedro, Delgado, Alves, PS, —, Sr, P...   \n",
       "12  [A, Sr, Ana, Catarina, Mendonça, Mendes, PS, —...   \n",
       "\n",
       "                                    normalized_tokens  \\\n",
       "1   [esa, sr, ana, catarin, mendonc, mend, ps, sra...   \n",
       "5   [sr, pedr, delg, alves, ps, sr, president, sra...   \n",
       "12  [sr, ana, catarin, mendonc, mend, ps, sr, pres...   \n",
       "\n",
       "    normalized_tokens_count  \\\n",
       "1                        90   \n",
       "5                       682   \n",
       "12                      271   \n",
       "\n",
       "                                            uni_grams  \\\n",
       "1   [esa, sr, ana, catarin, mendonc, mend, ps, sra...   \n",
       "5   [sr, pedr, delg, alves, ps, sr, president, sra...   \n",
       "12  [sr, ana, catarin, mendonc, mend, ps, sr, pres...   \n",
       "\n",
       "                                             bi_grams  \\\n",
       "1   [esa sr, sr ana, ana catarin, catarin mendonc,...   \n",
       "5   [sr pedr, pedr delg, delg alves, alves ps, ps ...   \n",
       "12  [sr ana, ana catarin, catarin mendonc, mendonc...   \n",
       "\n",
       "                                            tri_grams party_s  \\\n",
       "1   [esa sr ana, sr ana catarin, ana catarin mendo...      PS   \n",
       "5   [sr pedr delg, pedr delg alves, delg alves ps,...      PS   \n",
       "12  [sr ana catarin, ana catarin mendonc, catarin ...      PS   \n",
       "\n",
       "                          speaker  \n",
       "1   Ana Catarina Mendonça Mendes   \n",
       "5            Pedro Delgado Alves   \n",
       "12  Ana Catarina Mendonça Mendes   "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_df3=df3[df3.party_s.isin(right)]\n",
    "l_df3=df3[df3.party_s.isin(left)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14       [grã, sr, fern, negrã, psd, sr, president, hoj...\n",
       "20       [meirel, sr, cecíl, meirel, cdspp, sr, preside...\n",
       "21            [ssõ, sr, joã, pinh, alme, cdspp, muit, bem]\n",
       "22       [sr, cecíl, meirel, cdspp, cad, vez, fiz, form...\n",
       "40       [cdspp, ch, sr, adã, silv, psd, agor, vã, chov...\n",
       "                               ...                        \n",
       "21984         [sr, joã, pinh, alme, cdspp, senhor, govern]\n",
       "21986      [ps, sr, joã, pinh, alme, cdspp, tenh, vergonh]\n",
       "21989    [sab, sr, joã, pinh, alme, cdspp, convers, jog...\n",
       "21991    [dem, sr, joã, pinh, alme, cdspp, convers, jog...\n",
       "21993           [sr, joã, pinh, alme, cdspp, nã, vai, ter]\n",
       "Name: uni_grams, Length: 5111, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[df3.party_s.isin(right)].uni_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "right=[ 'PSD',  'CDS-PP', 'CH','IL','CDS']\n",
    "left=[ 'PS', 'BE', 'PCP', 'PAN', 'PEV','L','PCP']\n",
    "\n",
    "def create_frequency_table_grams(n_gram=1, input=df3, right_parties=right, left_parties=left):\n",
    "    grams_d={1: 'uni_grams', 2: 'bi_grams', 3: 'tri_grams'}\n",
    "    r_grams=[item for sublist in df3[df3.party_s.isin(right)][grams_d[n_gram]] for item in sublist]\n",
    "    l_grams=[item for sublist in df3[df3.party_s.isin(left)][grams_d[n_gram]] for item in sublist]\n",
    "\n",
    "    total_counter = Counter([item for sublist in df3[grams_d[n_gram]] for item in sublist])\n",
    "    right_counter = Counter(r_grams)\n",
    "    left_counter = Counter(l_grams)\n",
    "\n",
    "    df_all = pd.DataFrame.from_dict(total_counter, orient='index').reset_index()\n",
    "    df_all.columns=['phrase','count']\n",
    "    df_all['f_right']=[right_counter[x] for x in df_all.phrase]\n",
    "    df_all['f_left']=[left_counter[x] for x in df_all.phrase]\n",
    "\n",
    "    df_all['f_right_minus']=[f_all_except(right_counter, x) for x in df_all.phrase]\n",
    "    df_all['f_left_minus']=[f_all_except(left_counter, x) for x in df_all.phrase]\n",
    "    df_all['f_left_total']=get_total_party(left_counter)\n",
    "    df_all['f_right_total']=get_total_party(right_counter)\n",
    "\n",
    "    df_all['f_right_norm']=df_all['f_right']/df_all['f_right_total']\n",
    "    df_all['f_left_norm']=df_all['f_left']/df_all['f_left_total']\n",
    "\n",
    "    df_all['f_right_minus_norm']=df_all['f_right_minus']/df_all['f_right_total']\n",
    "    df_all['f_left_minus_norm']=df_all['f_left_minus']/df_all['f_left_total']\n",
    "\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def calculate_pearson(df_all):\n",
    "    aa=df_all['f_right_norm']*df_all['f_left_minus_norm'] \n",
    "    bb=df_all['f_left_norm']*df_all['f_right_minus_norm']\n",
    "    cc=aa-bb\n",
    "    dd=cc*cc\n",
    "    d11=df_all['f_right_norm']+df_all['f_left_norm']\n",
    "    d22=df_all['f_right_norm']+df_all['f_right_minus_norm']\n",
    "    d33=df_all['f_left_norm']+df_all['f_left_minus_norm']\n",
    "    d44=df_all['f_right_minus_norm']+df_all['f_left_minus_norm']\n",
    "    denom=d11*d22*d33*d44\n",
    "    pp=dd/denom\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=create_frequency_table_grams(n_gram=1, input=df3, right_parties=right, left_parties=left)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg2=create_frequency_table_grams(n_gram=2, input=df3, right_parties=right, left_parties=left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg3=create_frequency_table_grams(n_gram=3, input=df3, right_parties=right, left_parties=left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg2.to_pickle('dfg2.pkl') \n",
    "dfg3.to_pickle('dfg3.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg['pearson_quad']=calculate_pearson(dfg)\n",
    "dfg2['pearson_quad']=calculate_pearson(dfg2)\n",
    "dfg3['pearson_quad']=calculate_pearson(dfg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>count</th>\n",
       "      <th>f_right</th>\n",
       "      <th>f_left</th>\n",
       "      <th>f_right_minus</th>\n",
       "      <th>f_left_minus</th>\n",
       "      <th>f_left_total</th>\n",
       "      <th>f_right_total</th>\n",
       "      <th>f_right_norm</th>\n",
       "      <th>f_left_norm</th>\n",
       "      <th>f_right_minus_norm</th>\n",
       "      <th>f_left_minus_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>esa</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>268384</td>\n",
       "      <td>463452</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sr</td>\n",
       "      <td>24874</td>\n",
       "      <td>10587</td>\n",
       "      <td>14287</td>\n",
       "      <td>257799</td>\n",
       "      <td>449170</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>0.030827</td>\n",
       "      <td>0.960553</td>\n",
       "      <td>0.969173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ana</td>\n",
       "      <td>590</td>\n",
       "      <td>285</td>\n",
       "      <td>305</td>\n",
       "      <td>268101</td>\n",
       "      <td>463152</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.998938</td>\n",
       "      <td>0.999342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>catarin</td>\n",
       "      <td>317</td>\n",
       "      <td>63</td>\n",
       "      <td>254</td>\n",
       "      <td>268323</td>\n",
       "      <td>463203</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.999452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mendonc</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>111</td>\n",
       "      <td>268381</td>\n",
       "      <td>463346</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14988</th>\n",
       "      <td>serrã</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>268386</td>\n",
       "      <td>463456</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14989</th>\n",
       "      <td>demorous</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>268386</td>\n",
       "      <td>463456</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>desidrat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>268386</td>\n",
       "      <td>463456</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>conhecems</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>268386</td>\n",
       "      <td>463456</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>decadent</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>268386</td>\n",
       "      <td>463456</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14993 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          phrase  count  f_right  f_left  f_right_minus  f_left_minus  \\\n",
       "0            esa      7        2       5         268384        463452   \n",
       "1             sr  24874    10587   14287         257799        449170   \n",
       "2            ana    590      285     305         268101        463152   \n",
       "3        catarin    317       63     254         268323        463203   \n",
       "4        mendonc    116        5     111         268381        463346   \n",
       "...          ...    ...      ...     ...            ...           ...   \n",
       "14988      serrã      1        0       1         268386        463456   \n",
       "14989   demorous      1        0       1         268386        463456   \n",
       "14990   desidrat      1        0       1         268386        463456   \n",
       "14991  conhecems      1        0       1         268386        463456   \n",
       "14992   decadent      1        0       1         268386        463456   \n",
       "\n",
       "       f_left_total  f_right_total  f_right_norm  f_left_norm  \\\n",
       "0            463457         268386      0.000007     0.000011   \n",
       "1            463457         268386      0.039447     0.030827   \n",
       "2            463457         268386      0.001062     0.000658   \n",
       "3            463457         268386      0.000235     0.000548   \n",
       "4            463457         268386      0.000019     0.000240   \n",
       "...             ...            ...           ...          ...   \n",
       "14988        463457         268386      0.000000     0.000002   \n",
       "14989        463457         268386      0.000000     0.000002   \n",
       "14990        463457         268386      0.000000     0.000002   \n",
       "14991        463457         268386      0.000000     0.000002   \n",
       "14992        463457         268386      0.000000     0.000002   \n",
       "\n",
       "       f_right_minus_norm  f_left_minus_norm  \n",
       "0                0.999993           0.999989  \n",
       "1                0.960553           0.969173  \n",
       "2                0.998938           0.999342  \n",
       "3                0.999765           0.999452  \n",
       "4                0.999981           0.999760  \n",
       "...                   ...                ...  \n",
       "14988            1.000000           0.999998  \n",
       "14989            1.000000           0.999998  \n",
       "14990            1.000000           0.999998  \n",
       "14991            1.000000           0.999998  \n",
       "14992            1.000000           0.999998  \n",
       "\n",
       "[14993 rows x 12 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['pearson_quad']=calculate_pearson(df_all)\n",
    "df_all.sort_values(by=['pearson_quad'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams_d={1: 'uno_grams', 2: 'bi_grams', 3: 'tri_grams'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bi_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[esa sr, sr ana, ana catarin, catarin mendonc,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[sr pedr, pedr delg, delg alves, alves ps, ps ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[sr ana, ana catarin, catarin mendonc, mendonc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[grã sr, sr fern, fern negrã, negrã psd, psd s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[lie soar, soar sr, sr pedr, pedr fili, fili s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21984</th>\n",
       "      <td>[sr joã, joã pinh, pinh alme, alme cdspp, cdsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21986</th>\n",
       "      <td>[ps sr, sr joã, joã pinh, pinh alme, alme cdsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21989</th>\n",
       "      <td>[sab sr, sr joã, joã pinh, pinh alme, alme cds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21991</th>\n",
       "      <td>[dem sr, sr joã, joã pinh, pinh alme, alme cds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21993</th>\n",
       "      <td>[sr joã, joã pinh, pinh alme, alme cdspp, cdsp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12092 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                bi_grams\n",
       "1      [esa sr, sr ana, ana catarin, catarin mendonc,...\n",
       "5      [sr pedr, pedr delg, delg alves, alves ps, ps ...\n",
       "12     [sr ana, ana catarin, catarin mendonc, mendonc...\n",
       "14     [grã sr, sr fern, fern negrã, negrã psd, psd s...\n",
       "16     [lie soar, soar sr, sr pedr, pedr fili, fili s...\n",
       "...                                                  ...\n",
       "21984  [sr joã, joã pinh, pinh alme, alme cdspp, cdsp...\n",
       "21986  [ps sr, sr joã, joã pinh, pinh alme, alme cdsp...\n",
       "21989  [sab sr, sr joã, joã pinh, pinh alme, alme cds...\n",
       "21991  [dem sr, sr joã, joã pinh, pinh alme, alme cds...\n",
       "21993  [sr joã, joã pinh, pinh alme, alme cdspp, cdsp...\n",
       "\n",
       "[12092 rows x 1 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[[grams_d[2]]]\n",
    "\n",
    "df3[grams_d[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_all = pd.DataFrame.from_dict(total_counter, orient='index').reset_index()\n",
    "df_all.columns=['phrase','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['f_right']=[right_counter[x] for x in df_all.phrase]\n",
    "df_all['f_left']=[left_counter[x] for x in df_all.phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_all_except(counter_r_l, excp):\n",
    "    exclude_keys = [excp]\n",
    "    ans = [counter_r_l[k] for k in set(list(counter_r_l.keys())) - set(exclude_keys)]\n",
    "    return np.sum(ans)\n",
    "\n",
    "def get_total_party(counter_r_l):\n",
    "    ans = [counter_r_l[k] for k in list(counter_r_l.keys())]\n",
    "    return np.sum(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['f_right_minus']=[f_all_except(right_counter, x) for x in df_all.phrase]\n",
    "df_all['f_left_minus']=[f_all_except(left_counter, x) for x in df_all.phrase]\n",
    "df_all['f_left_total']=get_total_party(left_counter)\n",
    "df_all['f_right_total']=get_total_party(right_counter)\n",
    "\n",
    "df_all['f_right_norm']=df_all['f_right']/df_all['f_right_total']\n",
    "df_all['f_left_norm']=df_all['f_left']/df_all['f_left_total']\n",
    "\n",
    "df_all['f_right_minus_norm']=df_all['f_right_minus']/df_all['f_right_total']\n",
    "df_all['f_left_minus_norm']=df_all['f_left_minus']/df_all['f_left_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pearson(df_all):\n",
    "    aa=df_all['f_right_norm']*df_all['f_left_minus_norm'] \n",
    "    bb=df_all['f_left_norm']*df_all['f_right_minus_norm']\n",
    "    cc=aa-bb\n",
    "    dd=cc*cc\n",
    "    d11=df_all['f_right_norm']+df_all['f_left_norm']\n",
    "    d22=df_all['f_right_norm']+df_all['f_right_minus_norm']\n",
    "    d33=df_all['f_left_norm']+df_all['f_left_minus_norm']\n",
    "    d44=df_all['f_right_minus_norm']+df_all['f_left_minus_norm']\n",
    "    denom=d11*d22*d33*d44\n",
    "    pp=dd/denom\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['pearson_quad']=calculate_pearson(df_all)\n",
    "df_all.sort_values(by=['pearson_quad'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>count</th>\n",
       "      <th>f_right</th>\n",
       "      <th>f_left</th>\n",
       "      <th>f_right_minus</th>\n",
       "      <th>f_left_minus</th>\n",
       "      <th>f_left_total</th>\n",
       "      <th>f_right_total</th>\n",
       "      <th>f_right_norm</th>\n",
       "      <th>f_left_norm</th>\n",
       "      <th>f_right_minus_norm</th>\n",
       "      <th>f_left_minus_norm</th>\n",
       "      <th>pearson_quad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>psd</td>\n",
       "      <td>4893</td>\n",
       "      <td>3708</td>\n",
       "      <td>1185</td>\n",
       "      <td>264678</td>\n",
       "      <td>462272</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.013816</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.986184</td>\n",
       "      <td>0.997443</td>\n",
       "      <td>3.903199e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>cdspp</td>\n",
       "      <td>1782</td>\n",
       "      <td>1644</td>\n",
       "      <td>138</td>\n",
       "      <td>266742</td>\n",
       "      <td>463319</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.993874</td>\n",
       "      <td>0.999702</td>\n",
       "      <td>2.652234e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>pcp</td>\n",
       "      <td>3381</td>\n",
       "      <td>292</td>\n",
       "      <td>3089</td>\n",
       "      <td>268094</td>\n",
       "      <td>460368</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>0.998912</td>\n",
       "      <td>0.993335</td>\n",
       "      <td>2.013744e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ps</td>\n",
       "      <td>3913</td>\n",
       "      <td>466</td>\n",
       "      <td>3447</td>\n",
       "      <td>267920</td>\n",
       "      <td>460010</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>0.998264</td>\n",
       "      <td>0.992562</td>\n",
       "      <td>1.779745e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>be</td>\n",
       "      <td>1973</td>\n",
       "      <td>82</td>\n",
       "      <td>1891</td>\n",
       "      <td>268304</td>\n",
       "      <td>461566</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>0.999694</td>\n",
       "      <td>0.995920</td>\n",
       "      <td>1.627947e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>concert</td>\n",
       "      <td>71</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>268360</td>\n",
       "      <td>463412</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>1.258987e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>distânc</td>\n",
       "      <td>101</td>\n",
       "      <td>37</td>\n",
       "      <td>64</td>\n",
       "      <td>268349</td>\n",
       "      <td>463393</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>9.711563e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>comromet</td>\n",
       "      <td>109</td>\n",
       "      <td>40</td>\n",
       "      <td>69</td>\n",
       "      <td>268346</td>\n",
       "      <td>463388</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>4.187400e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>sobr</td>\n",
       "      <td>2599</td>\n",
       "      <td>953</td>\n",
       "      <td>1646</td>\n",
       "      <td>267433</td>\n",
       "      <td>461811</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.996449</td>\n",
       "      <td>0.996448</td>\n",
       "      <td>3.603611e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>flexibiliz</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>268375</td>\n",
       "      <td>463438</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>6.734136e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14993 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          phrase  count  f_right  f_left  f_right_minus  f_left_minus  \\\n",
       "107          psd   4893     3708    1185         264678        462272   \n",
       "644        cdspp   1782     1644     138         266742        463319   \n",
       "585          pcp   3381      292    3089         268094        460368   \n",
       "6             ps   3913      466    3447         267920        460010   \n",
       "111           be   1973       82    1891         268304        461566   \n",
       "...          ...    ...      ...     ...            ...           ...   \n",
       "1086     concert     71       26      45         268360        463412   \n",
       "3251     distânc    101       37      64         268349        463393   \n",
       "1221    comromet    109       40      69         268346        463388   \n",
       "893         sobr   2599      953    1646         267433        461811   \n",
       "4153  flexibiliz     30       11      19         268375        463438   \n",
       "\n",
       "      f_left_total  f_right_total  f_right_norm  f_left_norm  \\\n",
       "107         463457         268386      0.013816     0.002557   \n",
       "644         463457         268386      0.006126     0.000298   \n",
       "585         463457         268386      0.001088     0.006665   \n",
       "6           463457         268386      0.001736     0.007438   \n",
       "111         463457         268386      0.000306     0.004080   \n",
       "...            ...            ...           ...          ...   \n",
       "1086        463457         268386      0.000097     0.000097   \n",
       "3251        463457         268386      0.000138     0.000138   \n",
       "1221        463457         268386      0.000149     0.000149   \n",
       "893         463457         268386      0.003551     0.003552   \n",
       "4153        463457         268386      0.000041     0.000041   \n",
       "\n",
       "      f_right_minus_norm  f_left_minus_norm  pearson_quad  \n",
       "107             0.986184           0.997443  3.903199e-03  \n",
       "644             0.993874           0.999702  2.652234e-03  \n",
       "585             0.998912           0.993335  2.013744e-03  \n",
       "6               0.998264           0.992562  1.779745e-03  \n",
       "111             0.999694           0.995920  1.627947e-03  \n",
       "...                  ...                ...           ...  \n",
       "1086            0.999903           0.999903  1.258987e-10  \n",
       "3251            0.999862           0.999862  9.711563e-11  \n",
       "1221            0.999851           0.999851  4.187400e-11  \n",
       "893             0.996449           0.996448  3.603611e-11  \n",
       "4153            0.999959           0.999959  6.734136e-13  \n",
       "\n",
       "[14993 rows x 13 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['esa',\n",
       " 'sr',\n",
       " 'ana',\n",
       " 'catarin',\n",
       " 'mendonc',\n",
       " 'mend',\n",
       " 'ps',\n",
       " 'sras',\n",
       " 'srs',\n",
       " 'deut',\n",
       " 'nom',\n",
       " 'boa',\n",
       " 'rax',\n",
       " 'arlament',\n",
       " 'send',\n",
       " 'gru',\n",
       " 'maioritári',\n",
       " 'nest',\n",
       " 'assembl',\n",
       " 'reúblic',\n",
       " 'cabem',\n",
       " 'inic',\n",
       " 'trabalh',\n",
       " 'dest',\n",
       " 'nov',\n",
       " 'legislatur',\n",
       " 'mesm',\n",
       " 'gost',\n",
       " 'rimeir',\n",
       " 'lug',\n",
       " 'saud',\n",
       " 'tod',\n",
       " 'eleit',\n",
       " 'ara',\n",
       " 'cumr',\n",
       " 'aquel',\n",
       " 'reseit',\n",
       " 'intuiçã',\n",
       " 'democrát',\n",
       " 'cad',\n",
       " 'exerc',\n",
       " 'mandat',\n",
       " 'reresent',\n",
       " 'daquel',\n",
       " 'eleg',\n",
       " 'aqu',\n",
       " 'estar',\n",
       " 'parlament',\n",
       " 'part',\n",
       " 'social',\n",
       " 'muit',\n",
       " 'honr',\n",
       " 'design',\n",
       " 'resid',\n",
       " 'noss',\n",
       " 'sessã',\n",
       " 'eduard',\n",
       " 'ferr',\n",
       " 'rodrigu',\n",
       " 'rest',\n",
       " 'president',\n",
       " 'cessant',\n",
       " 'eço',\n",
       " 'sub',\n",
       " 'pedr',\n",
       " 'delg',\n",
       " 'alves',\n",
       " 'asso',\n",
       " 'entã',\n",
       " 'leitur',\n",
       " 'relatóri',\n",
       " 'arec',\n",
       " 'comissã',\n",
       " 'eventual',\n",
       " 'verific',\n",
       " 'pod',\n",
       " 'seguint',\n",
       " 'teor',\n",
       " 'dias',\n",
       " 'mês',\n",
       " 'outubr',\n",
       " 'hor',\n",
       " 'minut',\n",
       " 'reun',\n",
       " 'sal',\n",
       " 'paláci',\n",
       " 'sã',\n",
       " 'bent',\n",
       " 'roced',\n",
       " 'noscrit',\n",
       " 'i',\n",
       " 'séri',\n",
       " 'númer',\n",
       " 'oder',\n",
       " 'dia',\n",
       " 'xiv',\n",
       " 'reuniã',\n",
       " 'deliber',\n",
       " 'mes',\n",
       " 'constituíd',\n",
       " 'elo',\n",
       " 'fili',\n",
       " 'net',\n",
       " 'brandã',\n",
       " 'elos',\n",
       " 'carl',\n",
       " 'peixot',\n",
       " 'psd',\n",
       " 'jos',\n",
       " 'manuel',\n",
       " 'purez',\n",
       " 'be',\n",
       " 'vicepresident',\n",
       " 'seguid',\n",
       " 'relator',\n",
       " 'comuls',\n",
       " 'rocess',\n",
       " 'dem',\n",
       " 'element',\n",
       " 'envi',\n",
       " 'nacional',\n",
       " 'eleiçõ',\n",
       " 'atas',\n",
       " 'aurament',\n",
       " 'geral',\n",
       " 'ali',\n",
       " 'inclus',\n",
       " 'constatous',\n",
       " 'regular',\n",
       " 'formal',\n",
       " 'atribuiçã',\n",
       " 'conform',\n",
       " 'maa',\n",
       " 'oficial',\n",
       " 'n',\n",
       " 'ublic',\n",
       " 'diári',\n",
       " 'sulement',\n",
       " 'or',\n",
       " 'unanim',\n",
       " 'dev',\n",
       " 'ser',\n",
       " 'julg',\n",
       " 'constant',\n",
       " 'refer',\n",
       " 'list',\n",
       " 'tend',\n",
       " 'cont',\n",
       " 'disosiçõ',\n",
       " 'leg',\n",
       " 'alic',\n",
       " 'edid',\n",
       " 'substituiçã',\n",
       " 'aresent',\n",
       " 'substituiçõ',\n",
       " 'ertinent',\n",
       " 'carg',\n",
       " 'determin',\n",
       " 'susensã',\n",
       " 'artig',\n",
       " 'estatut',\n",
       " 'candidat',\n",
       " 'nã',\n",
       " 'concernent',\n",
       " 'artid',\n",
       " 'segu',\n",
       " 'ordem',\n",
       " 'recedent',\n",
       " 'reset',\n",
       " 'círcul',\n",
       " 'eleitor',\n",
       " 'salv',\n",
       " 'resent',\n",
       " 'dat',\n",
       " 'estej',\n",
       " 'abrang',\n",
       " 'imed',\n",
       " 'temorári',\n",
       " 'tenh',\n",
       " 'alín',\n",
       " 'iníci',\n",
       " 'corrent',\n",
       " 'inclusiv',\n",
       " 'nun',\n",
       " 'oliveir',\n",
       " 'sant',\n",
       " 'eleitoral',\n",
       " 'aveir',\n",
       " 'substituíd',\n",
       " 'brun',\n",
       " 'armand',\n",
       " 'aragã',\n",
       " 'henriqu',\n",
       " 'fern',\n",
       " 'gom',\n",
       " 'brag',\n",
       " 'mar',\n",
       " 'ribeir',\n",
       " 'silv',\n",
       " 'euric',\n",
       " 'jorg',\n",
       " 'nogueir',\n",
       " 'leit',\n",
       " 'brilhant',\n",
       " 'castel',\n",
       " 'branc',\n",
       " 'joan',\n",
       " 'morgadinh',\n",
       " 'mart',\n",
       " 'alexandr',\n",
       " 'fartur',\n",
       " 'alme',\n",
       " 'simõ',\n",
       " 'coimbr',\n",
       " 'joã',\n",
       " 'madeir',\n",
       " 'gouv',\n",
       " 'albin',\n",
       " 'rainh',\n",
       " 'ataíd',\n",
       " 'nev',\n",
       " 'raquel',\n",
       " 'fátim',\n",
       " 'cardos',\n",
       " 'ferreir',\n",
       " 'luís',\n",
       " 'caoul',\n",
       " 'évor',\n",
       " 'cát',\n",
       " 'sous',\n",
       " 'virtud',\n",
       " 'carmen',\n",
       " 'jesus',\n",
       " 'gerald',\n",
       " 'carvalheir',\n",
       " 'aolinári',\n",
       " 'port',\n",
       " 'far',\n",
       " 'lúc',\n",
       " 'pass',\n",
       " 'jerónim',\n",
       " 'loes',\n",
       " 'corr',\n",
       " 'godinh',\n",
       " 'guard',\n",
       " 'cristin',\n",
       " 'figueired',\n",
       " 'antóni',\n",
       " 'cost',\n",
       " 'lisbo',\n",
       " 'rit',\n",
       " 'mafald',\n",
       " 'nobr',\n",
       " 'borg',\n",
       " 'miguel',\n",
       " 'pardal',\n",
       " 'cabrit',\n",
       " 'marian',\n",
       " 'guimarã',\n",
       " 'vieir',\n",
       " 'diog',\n",
       " 'feij',\n",
       " 'leã',\n",
       " 'cam',\n",
       " 'mári',\n",
       " 'freit',\n",
       " 'centen',\n",
       " 'maçar',\n",
       " 'nicolau',\n",
       " 'grac',\n",
       " 'fonsec',\n",
       " 'caetan',\n",
       " 'gonçalv',\n",
       " 'estev',\n",
       " 'tav',\n",
       " 'mour',\n",
       " 'titternigton',\n",
       " 'cravinh',\n",
       " 'anastáci',\n",
       " 'paul',\n",
       " 'sof',\n",
       " 'pedros',\n",
       " 'antun',\n",
       " 'ver',\n",
       " 'raimund',\n",
       " 'brás',\n",
       " 'soeir',\n",
       " 'mat',\n",
       " 'fernand',\n",
       " 'albert',\n",
       " 'vitorin',\n",
       " 'sabin',\n",
       " 'gued',\n",
       " 'barroc',\n",
       " 'mel',\n",
       " 'pereir',\n",
       " 'carneir',\n",
       " 'isabel',\n",
       " 'andrad',\n",
       " 'soln',\n",
       " 'onet',\n",
       " 'barbos',\n",
       " 'velos',\n",
       " 'torr',\n",
       " 'coelh',\n",
       " 'ludomil',\n",
       " 'leitã',\n",
       " 'santarém',\n",
       " 'afons',\n",
       " 'céu',\n",
       " 'albuquerqu',\n",
       " 'lagriminh',\n",
       " 'arméni',\n",
       " 'nasciment',\n",
       " 'setúbal',\n",
       " 'araúj',\n",
       " 'saldanh',\n",
       " 'azeved',\n",
       " 'galamb',\n",
       " 'ricard',\n",
       " 'emanuel',\n",
       " 'martins',\n",
       " 'mourinh',\n",
       " 'félix',\n",
       " 'clar',\n",
       " 'guadin',\n",
       " 'vered',\n",
       " 'tiag',\n",
       " 'vian',\n",
       " 'vaz',\n",
       " 'carinteir',\n",
       " 'loureir',\n",
       " 'rebel',\n",
       " 'vis',\n",
       " 'mout',\n",
       " 'reis',\n",
       " 'august',\n",
       " 'ernest',\n",
       " 'euro',\n",
       " 'b',\n",
       " 'd',\n",
       " 'democrat',\n",
       " 'mach',\n",
       " 'admit',\n",
       " 'acord',\n",
       " 'document',\n",
       " 'examin',\n",
       " 'disõ',\n",
       " 'igual',\n",
       " 'mencion',\n",
       " 'substitut',\n",
       " 'assim',\n",
       " 'legitim',\n",
       " 'obrig',\n",
       " 'minh',\n",
       " 'alavr',\n",
       " 'reeleiçã',\n",
       " 'quer',\n",
       " 'sublinh',\n",
       " 'exress',\n",
       " 'votaçã',\n",
       " 'tev',\n",
       " 'demonstr',\n",
       " 'bem',\n",
       " 'exercíci',\n",
       " 'anterior',\n",
       " 'cas',\n",
       " 'instituiçõ',\n",
       " 'ercurs',\n",
       " 'reconhec',\n",
       " 'elev',\n",
       " 'mérit',\n",
       " 'semr',\n",
       " 'defes',\n",
       " 'liberdad',\n",
       " 'democrac',\n",
       " 'confer',\n",
       " 'desejarlh',\n",
       " 'bom',\n",
       " 'resident',\n",
       " 'dizerlh',\n",
       " 'orgulh',\n",
       " 'sej',\n",
       " 'res',\n",
       " 'segund',\n",
       " 'deix',\n",
       " 'vez',\n",
       " 'agradec',\n",
       " 'confi',\n",
       " 'dã',\n",
       " 'resons',\n",
       " 'altur',\n",
       " 'enorm',\n",
       " 'desafi',\n",
       " 'sociedad',\n",
       " 'mund',\n",
       " 'enfrent',\n",
       " 'saúd',\n",
       " 'desejandolh',\n",
       " 'continu',\n",
       " 'diálog',\n",
       " 'necessári',\n",
       " 'moment',\n",
       " 'hoj',\n",
       " 'cess',\n",
       " 'funçõ',\n",
       " 'articul',\n",
       " 'banc',\n",
       " 'esecial',\n",
       " 'lider',\n",
       " 'cés',\n",
       " 'grand',\n",
       " 'fez',\n",
       " 'difícil',\n",
       " 'alaus',\n",
       " 'mã',\n",
       " 'vind',\n",
       " 'feliz',\n",
       " 'ganh',\n",
       " 'imort',\n",
       " 'últim',\n",
       " 'anos',\n",
       " 'sent',\n",
       " 'têm',\n",
       " 'oul',\n",
       " 'assumid',\n",
       " 'ouc',\n",
       " 'valor',\n",
       " 'funçã',\n",
       " 'venh',\n",
       " 'intençã',\n",
       " 'desvaloriz',\n",
       " 'caben',\n",
       " 'defend',\n",
       " 'ael',\n",
       " 'assar',\n",
       " 'instituiçã',\n",
       " 'aquil',\n",
       " 'enquant',\n",
       " 'centr',\n",
       " 'discussã',\n",
       " 'olít',\n",
       " 'saib',\n",
       " 'sed',\n",
       " 'imrescind',\n",
       " 'voz',\n",
       " 'desej',\n",
       " 'grã',\n",
       " 'negrã',\n",
       " 'fest',\n",
       " 'orqu',\n",
       " 'estam',\n",
       " 'celebr',\n",
       " 'tom',\n",
       " 'osse',\n",
       " 'renov',\n",
       " 'vot',\n",
       " 'diret',\n",
       " 'ortugues',\n",
       " 'livr',\n",
       " 'mudanc',\n",
       " 'signific',\n",
       " 'constitu',\n",
       " 'entrad',\n",
       " 'fund',\n",
       " 'fundamental',\n",
       " 'fazers',\n",
       " 'edagog',\n",
       " 'risc',\n",
       " 'erder',\n",
       " 'lut',\n",
       " 'felicit',\n",
       " 'eleiçã',\n",
       " 'segur',\n",
       " 'indeendent',\n",
       " 'isençã',\n",
       " 'equidist',\n",
       " 'garant',\n",
       " 'decorr',\n",
       " 'felic',\n",
       " 'osiçã',\n",
       " 'frontal',\n",
       " 'leal',\n",
       " 'afirm',\n",
       " 'convicçõ',\n",
       " 'parabéns',\n",
       " 'maior',\n",
       " 'lie',\n",
       " 'soar',\n",
       " 'comec',\n",
       " 'saudál',\n",
       " 'certez',\n",
       " 'rend',\n",
       " 'conduçã',\n",
       " 'fundament',\n",
       " 'crei',\n",
       " 'exig',\n",
       " 'cumriment',\n",
       " 'not',\n",
       " 'reeleit',\n",
       " 'consciênc',\n",
       " 'bloc',\n",
       " 'esquerd',\n",
       " 'firm',\n",
       " 'convicçã',\n",
       " 'falt',\n",
       " 'nenhum',\n",
       " 'cham',\n",
       " 'país',\n",
       " 'olha',\n",
       " 'eser',\n",
       " 'lanc',\n",
       " 'sab',\n",
       " 'consegu',\n",
       " 'abrir',\n",
       " 'janel',\n",
       " 'diz',\n",
       " 'fech',\n",
       " 'escolh',\n",
       " 'garr',\n",
       " 'auster',\n",
       " 'imoss',\n",
       " 'inevit',\n",
       " 'mostrous',\n",
       " 'insuficient',\n",
       " 'ovo',\n",
       " 'diss',\n",
       " 'sábi',\n",
       " 'arte',\n",
       " 'dur',\n",
       " 'seman',\n",
       " 'med',\n",
       " 'dess',\n",
       " 'conquist',\n",
       " 'val',\n",
       " 'ena',\n",
       " 'resost',\n",
       " 'siml',\n",
       " 'ergunt',\n",
       " 'desígni',\n",
       " 'róx',\n",
       " 'quatr',\n",
       " 'resond',\n",
       " 'sim',\n",
       " 'arofund',\n",
       " 'recuer',\n",
       " 'rendiment',\n",
       " 'direit',\n",
       " 'ossível',\n",
       " 'ter',\n",
       " 'onde',\n",
       " 'geraçõ',\n",
       " 'dignidad',\n",
       " 'salári',\n",
       " 'just',\n",
       " 'servic',\n",
       " 'úblic',\n",
       " 'estã',\n",
       " 'reféns',\n",
       " 'met',\n",
       " 'défic',\n",
       " 'bruxel',\n",
       " 'àquel',\n",
       " 'acredit',\n",
       " 'caminh',\n",
       " 'cá',\n",
       " 'permitam',\n",
       " 'conclu',\n",
       " 'defin',\n",
       " 'erant',\n",
       " 'dar',\n",
       " 'assos',\n",
       " 'construçã',\n",
       " 'fact',\n",
       " 'melhor',\n",
       " 'mer',\n",
       " 'arêntes',\n",
       " 'ide',\n",
       " 'falh',\n",
       " 'homens',\n",
       " 'mulh',\n",
       " 'caus',\n",
       " 'nunc',\n",
       " 'engan',\n",
       " 'iveir',\n",
       " 'pcp',\n",
       " 'felicitál',\n",
       " 'faz',\n",
       " 'len',\n",
       " 'missã',\n",
       " 'invest',\n",
       " 'constituiçã',\n",
       " 'leis',\n",
       " 'regiment',\n",
       " 'intervençã',\n",
       " 'condiçõ',\n",
       " 'substancial',\n",
       " 'diferent',\n",
       " 'serã',\n",
       " 'men',\n",
       " 'exigent',\n",
       " 'onto',\n",
       " 'vist',\n",
       " 'necess',\n",
       " 'assegur',\n",
       " 'dê',\n",
       " 'exressã',\n",
       " 'concret',\n",
       " 'regim',\n",
       " 'cidadã',\n",
       " 'ortuguês',\n",
       " 'revolu',\n",
       " 'abril',\n",
       " 'consagr',\n",
       " 'objet',\n",
       " 'deend',\n",
       " 'decisõ',\n",
       " 'tant',\n",
       " 'cometent',\n",
       " 'entant',\n",
       " 'decis',\n",
       " 'alcanc',\n",
       " 'coloc',\n",
       " 'imediat',\n",
       " 'lev',\n",
       " 'long',\n",
       " 'erset',\n",
       " 'concretiz',\n",
       " 'verdadeir',\n",
       " 'altern',\n",
       " 'atriót',\n",
       " 'roblem',\n",
       " 'contribut',\n",
       " 'funcion',\n",
       " 'dignific',\n",
       " 'divergent',\n",
       " 'convergent',\n",
       " 'honest',\n",
       " 'disosiçã',\n",
       " 'cooeraçã',\n",
       " 'tal',\n",
       " 'assad',\n",
       " 'meirel',\n",
       " 'cecíl',\n",
       " 'cdspp',\n",
       " 'sinal',\n",
       " 'através',\n",
       " 'cds',\n",
       " 'rov',\n",
       " 'concord',\n",
       " 'exist',\n",
       " 'absolut',\n",
       " 'lealdad',\n",
       " 'institucional',\n",
       " 'carateriz',\n",
       " 'ouv',\n",
       " 'figur',\n",
       " 'estad',\n",
       " 'edir',\n",
       " 'lembr',\n",
       " 'sessõ',\n",
       " 'ssõ',\n",
       " 'pinh',\n",
       " 'fiz',\n",
       " 'form',\n",
       " 'autónom',\n",
       " 'imarcial',\n",
       " 'ode',\n",
       " 'cert',\n",
       " 'corresond',\n",
       " 'considerando',\n",
       " 'relaçã',\n",
       " 'transmit',\n",
       " 'discurs',\n",
       " 'dir',\n",
       " 'imarc',\n",
       " 'vári',\n",
       " 'portugal',\n",
       " 'baters',\n",
       " 'esforc',\n",
       " 'contr',\n",
       " 'fiscal',\n",
       " 'aror',\n",
       " 'sair',\n",
       " 'frent',\n",
       " 'recis',\n",
       " 'atraalh',\n",
       " 'fort',\n",
       " 'atu',\n",
       " 'aís',\n",
       " 'justic',\n",
       " 'ativ',\n",
       " 'transarent',\n",
       " 'aliás',\n",
       " 'toc',\n",
       " 'regulament',\n",
       " 'lobby',\n",
       " 'financ',\n",
       " 'duas',\n",
       " 'matér',\n",
       " 'colet',\n",
       " 'roteg',\n",
       " 'frac',\n",
       " 'desfavorec',\n",
       " 'cristã',\n",
       " 'esquec',\n",
       " 'termin',\n",
       " 'vam',\n",
       " 'diverg',\n",
       " 'normal',\n",
       " 'natural',\n",
       " 'exect',\n",
       " 'acontec',\n",
       " 'fac',\n",
       " 'ness',\n",
       " 'debat',\n",
       " 'acalor',\n",
       " 'fom',\n",
       " 'trat',\n",
       " 'uns',\n",
       " 'outr',\n",
       " 'signif',\n",
       " 'real',\n",
       " 'inês',\n",
       " 'pan',\n",
       " 'agor',\n",
       " 'soub',\n",
       " 'comlex',\n",
       " 'lural',\n",
       " 'inabal',\n",
       " 'rincíi',\n",
       " 'sucess',\n",
       " 'missõ',\n",
       " 'funcionár',\n",
       " 'funcionári',\n",
       " 'jornal',\n",
       " 'quotidian',\n",
       " 'connosc',\n",
       " 'dificuldad',\n",
       " 'marc',\n",
       " 'sécul',\n",
       " 'xxi',\n",
       " 'acresc',\n",
       " 'articular',\n",
       " 'relat',\n",
       " 'necessár',\n",
       " 'ossam',\n",
       " 'ultraass',\n",
       " 'aes',\n",
       " 'result',\n",
       " 'obtiv',\n",
       " 'term',\n",
       " 'odem',\n",
       " 'lament',\n",
       " 'tax',\n",
       " 'abstençã',\n",
       " 'derrot',\n",
       " 'combat',\n",
       " 'comromiss',\n",
       " 'acomanh',\n",
       " 'contribu',\n",
       " 'erceb',\n",
       " 'esso',\n",
       " 'artic',\n",
       " 'vid',\n",
       " 'ensar',\n",
       " 'oderm',\n",
       " 'rearoxim',\n",
       " 'hemicicl',\n",
       " 'vontad',\n",
       " 'soberan',\n",
       " 'encontr',\n",
       " 'comosiçã',\n",
       " 'reforc',\n",
       " 'aument',\n",
       " 'viv',\n",
       " 'hã',\n",
       " 'cheg',\n",
       " 'comrometemon',\n",
       " 'farol',\n",
       " 'obrez',\n",
       " 'desigualdad',\n",
       " 'soc',\n",
       " 'imulsion',\n",
       " 'arceir',\n",
       " 'equilíbri',\n",
       " 'sustent',\n",
       " 'avanc',\n",
       " 'étic',\n",
       " 'econom',\n",
       " 'açã',\n",
       " 'climát',\n",
       " 'relacion',\n",
       " 'lanet',\n",
       " 'reiter',\n",
       " 'saudaçã',\n",
       " 'pev',\n",
       " 'arranqu',\n",
       " 'aen',\n",
       " 'curt',\n",
       " 'ecolog',\n",
       " 'verd',\n",
       " 'sequênc',\n",
       " 'legisl',\n",
       " 'exat',\n",
       " 'roósit',\n",
       " 'fic',\n",
       " 'noçã',\n",
       " 'daquil',\n",
       " 'transit',\n",
       " 'atual',\n",
       " 'regress',\n",
       " 'convívi',\n",
       " 'lid',\n",
       " 'reocuaçõ',\n",
       " 'asir',\n",
       " 'equilibr',\n",
       " 'ambiental',\n",
       " 'sobretud',\n",
       " 'alter',\n",
       " 'ameac',\n",
       " 'destac',\n",
       " 'desd',\n",
       " 'anúnci',\n",
       " 'feit',\n",
       " 'rev',\n",
       " 'refirom',\n",
       " 'heloís',\n",
       " 'aolón',\n",
       " 'incans',\n",
       " 'durant',\n",
       " 'ambient',\n",
       " 'recurs',\n",
       " 'desenvolv',\n",
       " 'dirig',\n",
       " 'êxit',\n",
       " 'desemenh',\n",
       " 'tã',\n",
       " 'mant',\n",
       " 'habitu',\n",
       " 'fim',\n",
       " 'rocur',\n",
       " 'credibiliz',\n",
       " 'órgã',\n",
       " 'primeiroministr',\n",
       " 'record',\n",
       " 'assum',\n",
       " 'acrescent',\n",
       " 'estudant',\n",
       " 'existent',\n",
       " 'essencial',\n",
       " 'ninguém',\n",
       " 'estud',\n",
       " 'ensin',\n",
       " 'suerior',\n",
       " 'carênc',\n",
       " 'económ',\n",
       " 'ch',\n",
       " 'adã',\n",
       " 'vã',\n",
       " 'chov',\n",
       " 'comboi',\n",
       " 'boi',\n",
       " 'andré',\n",
       " 'ventur',\n",
       " 'agar',\n",
       " 'motor',\n",
       " 'sandrapereir',\n",
       " 'ah',\n",
       " 'ereir',\n",
       " 'rioridad',\n",
       " 'cuid',\n",
       " 'rimári',\n",
       " 'par',\n",
       " 'além',\n",
       " 'unidad',\n",
       " 'famili',\n",
       " 'cri',\n",
       " 'estarã',\n",
       " 'dezembr',\n",
       " 'ano',\n",
       " 'rous',\n",
       " 'generaliz',\n",
       " 'model',\n",
       " 'ro',\n",
       " 'perestrell',\n",
       " 'aind',\n",
       " 'comichã',\n",
       " 'ausênc',\n",
       " 'rui',\n",
       " 'rio',\n",
       " 'cumrimento',\n",
       " 'questã',\n",
       " 'sobr',\n",
       " 'govern',\n",
       " 'histór',\n",
       " 'deo',\n",
       " 'olém',\n",
       " 'solucion',\n",
       " 'quas',\n",
       " 'ajust',\n",
       " 'aí',\n",
       " 'psdo',\n",
       " 'membr',\n",
       " 'romoçã',\n",
       " 'desromoçã',\n",
       " 'ministr',\n",
       " 'camanh',\n",
       " 'ronald',\n",
       " 'portant',\n",
       " 'desromov',\n",
       " 'hierarqu',\n",
       " 'sequ',\n",
       " 'agend',\n",
       " 'vai',\n",
       " 'fal',\n",
       " 'emblem',\n",
       " 'máxim',\n",
       " 'v',\n",
       " 'ex',\n",
       " 'tinh',\n",
       " 'protest',\n",
       " 'novidad',\n",
       " 'atrás',\n",
       " 'des',\n",
       " 'secretári',\n",
       " 'energ',\n",
       " 'adjunt',\n",
       " 'ortant',\n",
       " 'ministéri',\n",
       " 'vim',\n",
       " 'notíc',\n",
       " 'exlor',\n",
       " 'líti',\n",
       " 'nort',\n",
       " 'deu',\n",
       " 'concessã',\n",
       " 'emres',\n",
       " 'três',\n",
       " 'junt',\n",
       " 'fregues',\n",
       " 'sid',\n",
       " 'mínim',\n",
       " 'caital',\n",
       " 'anónim',\n",
       " 'negóci',\n",
       " 'milhõ',\n",
       " 'eur',\n",
       " 'concession',\n",
       " 'imact',\n",
       " 'quand',\n",
       " 'antes',\n",
       " 'covilhã',\n",
       " 'atribu',\n",
       " 'hav',\n",
       " 'romov',\n",
       " 'câm',\n",
       " 'lan',\n",
       " 'legal',\n",
       " 'agiu',\n",
       " 'qualqu',\n",
       " 'mac',\n",
       " 'duraçã',\n",
       " 'indic',\n",
       " 'questõ',\n",
       " 'del',\n",
       " 'tud',\n",
       " 'mal',\n",
       " 'razã',\n",
       " 'escrev',\n",
       " 'program',\n",
       " 'jam',\n",
       " 'arcer',\n",
       " 'úblicoriv',\n",
       " 'ppp',\n",
       " 'agrad',\n",
       " 'desagrad',\n",
       " 'lei',\n",
       " 'bas',\n",
       " 'cois',\n",
       " 'híbr',\n",
       " 'desagr',\n",
       " 'setor',\n",
       " 'moder',\n",
       " 'aarec',\n",
       " 'riv',\n",
       " 'dig',\n",
       " 'gestã',\n",
       " 'hosital',\n",
       " 'eficaz',\n",
       " 'dinheir',\n",
       " 'situaçõ',\n",
       " 'caos',\n",
       " 'manutençã',\n",
       " 'reduz',\n",
       " 'consult',\n",
       " 'cirurg',\n",
       " 'sincer',\n",
       " 'entend',\n",
       " 'tabu',\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in df_all.phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>esa</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sr</td>\n",
       "      <td>24874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ana</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>catarin</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mendonc</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14988</th>\n",
       "      <td>serrã</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14989</th>\n",
       "      <td>demorous</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>desidrat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>conhecems</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>decadent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14993 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          phrase  count\n",
       "0            esa      7\n",
       "1             sr  24874\n",
       "2            ana    590\n",
       "3        catarin    317\n",
       "4        mendonc    116\n",
       "...          ...    ...\n",
       "14988      serrã      1\n",
       "14989   demorous      1\n",
       "14990   desidrat      1\n",
       "14991  conhecems      1\n",
       "14992   decadent      1\n",
       "\n",
       "[14993 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a5ab6f8988138c4aafa838927270364e946a56a2b152cd75ab864ac6056d77"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
