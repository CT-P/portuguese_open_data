{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import validators\n",
    "import datetime\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\caperei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downloads\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('rslp')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "characters_for_name=60\n",
    "legislature='dar/01'\n",
    "cycle='14'\n",
    "\n",
    "stop_words_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "#stop_words = [\"the\",\"it\",\"she\",\"he\", \"a\"] #Uncomment this line if you want to use your own list of stopwords.\n",
    "#The stemmers and lemmers need to be initialized before bing run\n",
    "#porter = nltk.stem.porter.PorterStemmer()\n",
    "snowball = nltk.stem.snowball.SnowballStemmer('portuguese')\n",
    "#wordnet = nltk.stem.WordNetLemmatizer()\n",
    "#RSLP=nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "def add_zeros(int_):\n",
    "    if len(str(int_))<2:\n",
    "        return '00'+str(int_)\n",
    "    if len(str(int_))<3:\n",
    "        return '0'+str(int_)\n",
    "    if len(str(int_))==3:\n",
    "        return str(int_)\n",
    "\n",
    "def get_text_from_html(url__):\n",
    "    from bs4 import BeautifulSoup\n",
    "    res = requests.get(url__)\n",
    "    html_page = res.content\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "    return str(soup.noscript)\n",
    "\n",
    "def read_input_table(current_directory=\"C:\\\\Users\\caperei\",cycle='14',session='1' ):\n",
    "\n",
    "    data_directory=f\"\\portuguese_open_data\\data\\cycle\\{cycle}\\session\\{session}\\\\numbers_dates_pages.csv\"\n",
    "    input_data=pd.read_csv(r\"C:\\Users\\caperei\\portuguese_open_data\\data\\cyle\\14\\session\\1\\numbers_dates_pages.csv\")\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex\n",
    "def check_dialog(text_):\n",
    "    pat=\"(?:</p><p>.*?\\(.*?\\): —)\"\n",
    "    match=re.findall(pat, text_)\n",
    "    if match is None :\n",
    "        return 'no_dialog'\n",
    "    else:\n",
    "        for m in match:\n",
    "            \n",
    "            return m\n",
    "\n",
    "def extract_dialog(full_text,characters_for_name):    \n",
    "    if full_text is None:\n",
    "        return None\n",
    "    else:\n",
    "        dialogs=[(m.start(0), m.end(0)) for m in re.finditer('</p><p></p><p>(.+?): —', full_text)]\n",
    "        out=[]\n",
    "        if len(dialogs)==1:\n",
    "            out.append(full_text[dialogs[0][1]-characters_for_name:])\n",
    "        if len(dialogs)>1:\n",
    "            for i in range(0, len(dialogs)-1):\n",
    "                out.append(full_text[dialogs[i][1]-characters_for_name:dialogs[i+1][0]])\n",
    "            out.append(full_text[dialogs[len(dialogs)-1][1]-50:])\n",
    "        return out\n",
    "\n",
    "    \n",
    "def extract_party_name(dialogs):\n",
    "    if dialogs is None:\n",
    "        return None\n",
    "    else:\n",
    "        res=[]\n",
    "        for i in dialogs:\n",
    "                    positions=[(m.start(0), m.end(0)) for m in re.finditer('\\((.+?)\\): —', i)]\n",
    "                    if len(positions)==0:\n",
    "                        res.append(['No','No'])\n",
    "                    else:\n",
    "                        party=re.findall('\\((.+?)\\)',i)\n",
    "                        name_aux=i[positions[0][1]-50:positions[0][1]]\n",
    "                        name=re.sub(r'\\b\\w{1,2}\\b', '', name_aux).replace('.','').replace ('()','').replace('  ','').replace('<','').replace('>','').replace('/','').replace(': —','')\n",
    "                        if len(party)>0:\n",
    "                            party=party[0]\n",
    "                        res.append([party,name])\n",
    "        return res\n",
    "\n",
    "def add_speech_next_page(df):\n",
    "    for pi in range(1,df.page.max()+1):\n",
    "        if len(df[df.page==pi].speech.values[0])>0:\n",
    "            speeches=df[df.page==pi].speech.values[0]\n",
    "            if '</noscript>' in speeches[-1]:\n",
    "                \n",
    "                for n in range(1,df.page.max()-pi):\n",
    "                    if ': —' in df[df.page==pi+n].text_1.values[0]:\n",
    "                        \n",
    "                        in_=df[df.page==pi+n].text_1.values[0].find(': —')\n",
    "                        df[df.page==pi].speech.values[0][-1]=df[df.page==pi].speech.values[0][-1]+' '+str(df[df.page==pi+n].text_1.values[0][0:in_])\n",
    "                        \n",
    "                        break\n",
    "                    else:\n",
    "                        \n",
    "                        df[df.page==pi].speech.values[0][-1]=df[df.page==pi].speech.values[0][-1]+' '+str(df[df.page==pi+n].text_1.values[0])\n",
    "    return df\n",
    "\n",
    "\n",
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "  if(type(text)==float):\n",
    "    return text\n",
    "  ans=\"\"  \n",
    "  for i in text:     \n",
    "    if i not in string.punctuation+'<p></p>ºª':\n",
    "      ans+=i    \n",
    "  return ans\n",
    "\n",
    "def normlizeTokens(tokenLst, stopwordLst = None, stemmer = None):\n",
    "    #We can use a generator here as we just need to iterate over it\n",
    "\n",
    "    #Lowering the case and removing non-words\n",
    "    workingIter = (w.lower() for w in tokenLst if w.isalpha())\n",
    "\n",
    "    #Now we can use the semmer, if provided\n",
    "    if stemmer is not None:\n",
    "        workingIter = (stemmer.stem(w) for w in workingIter)\n",
    "         \n",
    "    #And remove the stopwords\n",
    "    if stopwordLst is not None:\n",
    "        workingIter = (w for w in workingIter if w not in stopwordLst)\n",
    "    #We will return a list with the stopwords removed\n",
    "    return list(workingIter)\n",
    "\n",
    "def generate_N_grams(text,ngram=1):\n",
    "  words=[word for word in text]  \n",
    "  temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "  ans=[' '.join(ngram) for ngram in temp]\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions scrapping\n",
    "def build_transcripts_table_from_html(session=['01'],legislature='dar/01', cycle='14'):\n",
    "    df = pd.DataFrame(columns=['legislature','cycle','session','number','date','page', 'text_1','url'])        \n",
    "    #session=['01'] #['01','02','03']\n",
    "    numbers_dates=list(zip(input_data.number, input_data.date,input_data.pages )) #[0:1]\n",
    "    pages=input_data.pages.values #[0:1]\n",
    "    s_c=[]\n",
    "    n_c=[]\n",
    "    d_c=[]\n",
    "    p_c=[]\n",
    "    u_c=[]\n",
    "    t_c=[]\n",
    "    for s in session:\n",
    "        for number, date, page in numbers_dates:\n",
    "            number=add_zeros(number)\n",
    "            date=datetime.datetime.strptime(date, '%d/%m/%Y').strftime('%Y-%m-%d')\n",
    "            for page_i in range(1,page+1):\n",
    "                    url_=f'https://debates.parlamento.pt/catalogo/r3/{legislature}/{cycle}/{s}/{number}/{date}/{page_i}'\n",
    "                    if validators.url(url_):\n",
    "                        #print (url_)\n",
    "                        u_c.append(url_)\n",
    "                        p_c.append(page_i)\n",
    "                        t_c.append(get_text_from_html(url_))\n",
    "                        s_c.append(s)\n",
    "                        n_c.append(number)\n",
    "                        d_c.append(date)\n",
    "    df['page']=p_c\n",
    "    df['session']=s_c\n",
    "    df['number']=n_c\n",
    "    df['date']=d_c\n",
    "\n",
    "    df['text_1']=t_c\n",
    "    df['url']=u_c\n",
    "    df['legislature']=legislature\n",
    "    df['cycle']=cycle    \n",
    "    return df\n",
    "\n",
    "def add_party_speaker(df,characters_for_name ):\n",
    "    #add columns\n",
    "    df['speech']=[extract_dialog(t,characters_for_name) for t in df.text_1 ]\n",
    "    df['party']=[extract_party_name(t) for t in df.speech ]\n",
    "    df=add_speech_next_page(df)\n",
    "    #re arrange by speaker and party\n",
    "    df1=df.explode(['speech', 'party']).reset_index(drop=True)\n",
    "    df2=df1.dropna(subset=['party'])\n",
    "    df2['party_s']=[t[0] for t in df2.party]\n",
    "    df2['speaker']=[t[1] for t in df2.party]\n",
    "    df2=df2[df2.party_s!='No']\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>date</th>\n",
       "      <th>pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25/10/2019</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>30/10/2019</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>31/10/2019</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number        date  pages\n",
       "0       1  25/10/2019     13\n",
       "1       2  30/10/2019    124\n",
       "2       3  31/10/2019     26"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data=read_input_table()\n",
    "input_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=build_transcripts_table_from_html()\n",
    "#df.to_pickle('portuguese_transcripts_s1.pkl') \n",
    "df = pd.read_pickle('portuguese_transcripts_s1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legislature</th>\n",
       "      <th>cycle</th>\n",
       "      <th>session</th>\n",
       "      <th>number</th>\n",
       "      <th>date</th>\n",
       "      <th>page</th>\n",
       "      <th>text_1</th>\n",
       "      <th>url</th>\n",
       "      <th>speech</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;Sábado, 26 de outubro de 2019  ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[es.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;A Sr.ª Ana Catarina Mendonça...</td>\n",
       "      <td>[[PS, Ana Catarina Mendonça Mendes ], [No, No]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;26 DE OUTUBRO DE 2019 &lt;/p&gt;&lt;p&gt;3 ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[er votado, Sr. Presidente. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr...</td>\n",
       "      <td>[[No, No], [PS,  Pedro Delgado Alves ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;26 DE OUTUBRO DE 2019 &lt;/p&gt;&lt;p&gt;5 ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>[residente, muito obrigado. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr...</td>\n",
       "      <td>[[No, No]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  legislature cycle session number        date  page  \\\n",
       "0      dar/01    14      01    001  2019-10-25     1   \n",
       "1      dar/01    14      01    001  2019-10-25     2   \n",
       "2      dar/01    14      01    001  2019-10-25     3   \n",
       "3      dar/01    14      01    001  2019-10-25     4   \n",
       "4      dar/01    14      01    001  2019-10-25     5   \n",
       "\n",
       "                                              text_1  \\\n",
       "0  <noscript>\\n<p>Sábado, 26 de outubro de 2019  ...   \n",
       "1  <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "2  <noscript>\\n<p>26 DE OUTUBRO DE 2019 </p><p>3 ...   \n",
       "3  <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "4  <noscript>\\n<p>26 DE OUTUBRO DE 2019 </p><p>5 ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "1  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "2  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "3  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "4  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "\n",
       "                                              speech  \\\n",
       "0                                                 []   \n",
       "1  [es.</p><p></p><p>A Sr.ª Ana Catarina Mendonça...   \n",
       "2  [er votado, Sr. Presidente. </p><p></p><p>O Sr...   \n",
       "3                                                 []   \n",
       "4  [residente, muito obrigado. </p><p></p><p>O Sr...   \n",
       "\n",
       "                                               party  \n",
       "0                                                 []  \n",
       "1  [[PS, Ana Catarina Mendonça Mendes ], [No, No]...  \n",
       "2            [[No, No], [PS,  Pedro Delgado Alves ]]  \n",
       "3                                                 []  \n",
       "4                                         [[No, No]]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-99982d4d3f5c>:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['party_s']=[t[0] for t in df2.party]\n",
      "<ipython-input-6-99982d4d3f5c>:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['speaker']=[t[1] for t in df2.party]\n"
     ]
    }
   ],
   "source": [
    "df2=add_party_speaker(df,characters_for_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['speech1']= df2['speech'].apply(lambda x:remove_punctuation(x))\n",
    "df2['tokenized_text'] = df2['speech1'].apply(lambda x: nltk.word_tokenize(x))\n",
    "df2['normalized_tokens'] = df2['tokenized_text'].apply(lambda x: normlizeTokens(x, stopwordLst = stop_words_nltk, stemmer = snowball))\n",
    "df2['normalized_tokens_count'] = df2['normalized_tokens'].apply(lambda x: len(x))\n",
    "df2['uni_grams'] = df2['normalized_tokens'].apply(lambda x: generate_N_grams(x,1))\n",
    "df2['bi_grams'] = df2['normalized_tokens'].apply(lambda x: generate_N_grams(x,2))\n",
    "df2['tri_grams'] = df2['normalized_tokens'].apply(lambda x: generate_N_grams(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.party_s.unique()\n",
    "parties=['PS', 'PSD', 'BE', 'PCP', 'CDS-PP', 'PAN', 'PEV','CH','IL','L','CDS','PCP']\n",
    "df3=df2[df2.party_s.isin(parties)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legislature</th>\n",
       "      <th>cycle</th>\n",
       "      <th>session</th>\n",
       "      <th>number</th>\n",
       "      <th>date</th>\n",
       "      <th>page</th>\n",
       "      <th>text_1</th>\n",
       "      <th>url</th>\n",
       "      <th>speech</th>\n",
       "      <th>party</th>\n",
       "      <th>party_s</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech1</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>normalized_tokens</th>\n",
       "      <th>normalized_tokens_count</th>\n",
       "      <th>uni_grams</th>\n",
       "      <th>bi_grams</th>\n",
       "      <th>tri_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>es.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;A Sr.ª Ana Catarina Mendonça ...</td>\n",
       "      <td>[PS, Ana Catarina Mendonça Mendes ]</td>\n",
       "      <td>PS</td>\n",
       "      <td>Ana Catarina Mendonça Mendes</td>\n",
       "      <td>esA Sr Ana Catarina Mendonça Mendes PS — Sras ...</td>\n",
       "      <td>[esA, Sr, Ana, Catarina, Mendonça, Mendes, PS,...</td>\n",
       "      <td>[esa, sr, ana, catarin, mendonc, mend, ps, sra...</td>\n",
       "      <td>90</td>\n",
       "      <td>[esa, sr, ana, catarin, mendonc, mend, ps, sra...</td>\n",
       "      <td>[esa sr, sr ana, ana catarin, catarin mendonc,...</td>\n",
       "      <td>[esa sr ana, sr ana catarin, ana catarin mendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;26 DE OUTUBRO DE 2019 &lt;/p&gt;&lt;p&gt;3 ...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>o. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;O Sr. Pedro Delgado Alves (PS...</td>\n",
       "      <td>[PS,  Pedro Delgado Alves ]</td>\n",
       "      <td>PS</td>\n",
       "      <td>Pedro Delgado Alves</td>\n",
       "      <td>o O Sr Pedro Delgado Alves PS — Sr Presidente ...</td>\n",
       "      <td>[o, O, Sr, Pedro, Delgado, Alves, PS, —, Sr, P...</td>\n",
       "      <td>[sr, pedr, delg, alves, ps, sr, president, sra...</td>\n",
       "      <td>682</td>\n",
       "      <td>[sr, pedr, delg, alves, ps, sr, president, sra...</td>\n",
       "      <td>[sr pedr, pedr delg, delg alves, alves ps, ps ...</td>\n",
       "      <td>[sr pedr delg, pedr delg alves, delg alves ps,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dar/01</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;noscript&gt;\\n&lt;p&gt;I SÉRIE — NÚMERO 1 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://debates.parlamento.pt/catalogo/r3/dar/...</td>\n",
       "      <td>&lt;/p&gt;&lt;p&gt;A Sr.ª Ana Catarina Mendonça Mendes (PS...</td>\n",
       "      <td>[PS, Ana Catarina Mendonça Mendes ]</td>\n",
       "      <td>PS</td>\n",
       "      <td>Ana Catarina Mendonça Mendes</td>\n",
       "      <td>A Sr Ana Catarina Mendonça Mendes PS — Sr Pres...</td>\n",
       "      <td>[A, Sr, Ana, Catarina, Mendonça, Mendes, PS, —...</td>\n",
       "      <td>[sr, ana, catarin, mendonc, mend, ps, sr, pres...</td>\n",
       "      <td>271</td>\n",
       "      <td>[sr, ana, catarin, mendonc, mend, ps, sr, pres...</td>\n",
       "      <td>[sr ana, ana catarin, catarin mendonc, mendonc...</td>\n",
       "      <td>[sr ana catarin, ana catarin mendonc, catarin ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   legislature cycle session number        date  page  \\\n",
       "1       dar/01    14      01    001  2019-10-25     2   \n",
       "5       dar/01    14      01    001  2019-10-25     3   \n",
       "12      dar/01    14      01    001  2019-10-25     8   \n",
       "\n",
       "                                               text_1  \\\n",
       "1   <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "5   <noscript>\\n<p>26 DE OUTUBRO DE 2019 </p><p>3 ...   \n",
       "12  <noscript>\\n<p>I SÉRIE — NÚMERO 1 </p><p></p><...   \n",
       "\n",
       "                                                  url  \\\n",
       "1   https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "5   https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "12  https://debates.parlamento.pt/catalogo/r3/dar/...   \n",
       "\n",
       "                                               speech  \\\n",
       "1   es.</p><p></p><p>A Sr.ª Ana Catarina Mendonça ...   \n",
       "5   o. </p><p></p><p>O Sr. Pedro Delgado Alves (PS...   \n",
       "12  </p><p>A Sr.ª Ana Catarina Mendonça Mendes (PS...   \n",
       "\n",
       "                                  party party_s  \\\n",
       "1   [PS, Ana Catarina Mendonça Mendes ]      PS   \n",
       "5           [PS,  Pedro Delgado Alves ]      PS   \n",
       "12  [PS, Ana Catarina Mendonça Mendes ]      PS   \n",
       "\n",
       "                          speaker  \\\n",
       "1   Ana Catarina Mendonça Mendes    \n",
       "5            Pedro Delgado Alves    \n",
       "12  Ana Catarina Mendonça Mendes    \n",
       "\n",
       "                                              speech1  \\\n",
       "1   esA Sr Ana Catarina Mendonça Mendes PS — Sras ...   \n",
       "5   o O Sr Pedro Delgado Alves PS — Sr Presidente ...   \n",
       "12  A Sr Ana Catarina Mendonça Mendes PS — Sr Pres...   \n",
       "\n",
       "                                       tokenized_text  \\\n",
       "1   [esA, Sr, Ana, Catarina, Mendonça, Mendes, PS,...   \n",
       "5   [o, O, Sr, Pedro, Delgado, Alves, PS, —, Sr, P...   \n",
       "12  [A, Sr, Ana, Catarina, Mendonça, Mendes, PS, —...   \n",
       "\n",
       "                                    normalized_tokens  \\\n",
       "1   [esa, sr, ana, catarin, mendonc, mend, ps, sra...   \n",
       "5   [sr, pedr, delg, alves, ps, sr, president, sra...   \n",
       "12  [sr, ana, catarin, mendonc, mend, ps, sr, pres...   \n",
       "\n",
       "    normalized_tokens_count  \\\n",
       "1                        90   \n",
       "5                       682   \n",
       "12                      271   \n",
       "\n",
       "                                            uni_grams  \\\n",
       "1   [esa, sr, ana, catarin, mendonc, mend, ps, sra...   \n",
       "5   [sr, pedr, delg, alves, ps, sr, president, sra...   \n",
       "12  [sr, ana, catarin, mendonc, mend, ps, sr, pres...   \n",
       "\n",
       "                                             bi_grams  \\\n",
       "1   [esa sr, sr ana, ana catarin, catarin mendonc,...   \n",
       "5   [sr pedr, pedr delg, delg alves, alves ps, ps ...   \n",
       "12  [sr ana, ana catarin, catarin mendonc, mendonc...   \n",
       "\n",
       "                                            tri_grams  \n",
       "1   [esa sr ana, sr ana catarin, ana catarin mendo...  \n",
       "5   [sr pedr delg, pedr delg alves, delg alves ps,...  \n",
       "12  [sr ana catarin, ana catarin mendonc, catarin ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "right=[ 'PSD',  'CDS-PP', 'CH','IL','CDS']\n",
    "left=[ 'PS', 'BE', 'PCP', 'PAN', 'PEV','L','PCP']\n",
    "\n",
    "\n",
    "def create_frequency_table_grams(n_gram=1, input=df3, right_parties=right, left_parties=left):\n",
    "    grams_d={1: 'uni_grams', 2: 'bi_grams', 3: 'tri_grams'}\n",
    "   \n",
    "\n",
    "    r_grams=[item for sublist in df3[df3.party_s.isin(right)][grams_d[n_gram]] for item in sublist]\n",
    "    l_grams=[item for sublist in df3[df3.party_s.isin(left)][grams_d[n_gram]] for item in sublist]\n",
    "\n",
    "    total_counter = Counter([item for sublist in df3[grams_d[n_gram]] for item in sublist])\n",
    "    right_counter = Counter(r_grams)\n",
    "    left_counter = Counter(l_grams)\n",
    "\n",
    "    df_all = pd.DataFrame.from_dict(total_counter, orient='index').reset_index()\n",
    "    df_all.columns=['phrase','count']\n",
    "    df_all['f_right']=[right_counter[x] for x in df_all.phrase]\n",
    "    df_all['f_left']=[left_counter[x] for x in df_all.phrase]\n",
    "\n",
    "\n",
    "    df_all['f_left_total']=sum(left_counter.values())\n",
    "    df_all['f_right_total']=sum(right_counter.values())\n",
    "    df_all['f_right_minus']=(df_all['f_right']- df_all['f_right_total'])/df_all['f_right_total']\n",
    "    df_all['f_left_minus']=(df_all['f_left']- df_all['f_left_total'])/df_all['f_left_total']\n",
    "\n",
    "    df_all['f_right_norm']=df_all['f_right']/df_all['f_right_total']\n",
    "    df_all['f_left_norm']=df_all['f_left']/df_all['f_left_total']\n",
    "\n",
    "    df_all['f_right_minus_norm']=df_all['f_right_minus']/df_all['f_right_total']\n",
    "    df_all['f_left_minus_norm']=df_all['f_left_minus']/df_all['f_left_total']\n",
    "\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def calculate_pearson(df_all):\n",
    "    aa=df_all['f_right_norm']*df_all['f_left_minus_norm'] \n",
    "    bb=df_all['f_left_norm']*df_all['f_right_minus_norm']\n",
    "    cc=aa-bb\n",
    "    dd=cc*cc\n",
    "    d11=df_all['f_right_norm']+df_all['f_left_norm']\n",
    "    d22=df_all['f_right_norm']+df_all['f_right_minus_norm']\n",
    "    d33=df_all['f_left_norm']+df_all['f_left_minus_norm']\n",
    "    d44=df_all['f_right_minus_norm']+df_all['f_left_minus_norm']\n",
    "    denom=d11*d22*d33*d44\n",
    "    pp=dd/denom\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=create_frequency_table_grams(n_gram=1, input=df3, right_parties=right, left_parties=left)\n",
    "dfg2=create_frequency_table_grams(n_gram=2, input=df3, right_parties=right, left_parties=left)\n",
    "dfg3=create_frequency_table_grams(n_gram=3, input=df3, right_parties=right, left_parties=left)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg2.to_pickle('dfg2.pkl') \n",
    "dfg3.to_pickle('dfg3.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg['pearson_quad']=calculate_pearson(dfg)\n",
    "dfg2['pearson_quad']=calculate_pearson(dfg2)\n",
    "dfg3['pearson_quad']=calculate_pearson(dfg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_table=dfg3[dfg3.pearson_quad>0]\n",
    "bigrams_table=dfg2[dfg2.pearson_quad>0]\n",
    "unigrams_table=dfg[dfg.pearson_quad>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>count</th>\n",
       "      <th>f_right</th>\n",
       "      <th>f_left</th>\n",
       "      <th>f_left_total</th>\n",
       "      <th>f_right_total</th>\n",
       "      <th>f_right_minus</th>\n",
       "      <th>f_left_minus</th>\n",
       "      <th>f_right_norm</th>\n",
       "      <th>f_left_norm</th>\n",
       "      <th>f_right_minus_norm</th>\n",
       "      <th>f_left_minus_norm</th>\n",
       "      <th>pearson_quad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cabem</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.949910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>intuiçã</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>293495.409252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>cessant</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>293495.409252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>xiv</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.844365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>seguid</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.949910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14988</th>\n",
       "      <td>serrã</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>293495.409252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14989</th>\n",
       "      <td>demorous</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>293495.409252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>desidrat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>293495.409252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>conhecems</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>293495.409252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>decadent</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>463457</td>\n",
       "      <td>268386</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>293495.409252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7554 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          phrase  count  f_right  f_left  f_left_total  f_right_total  \\\n",
       "20         cabem      3        0       3        463457         268386   \n",
       "37       intuiçã      1        0       1        463457         268386   \n",
       "61       cessant      1        0       1        463457         268386   \n",
       "95           xiv      4        0       4        463457         268386   \n",
       "113       seguid      3        0       3        463457         268386   \n",
       "...          ...    ...      ...     ...           ...            ...   \n",
       "14988      serrã      1        0       1        463457         268386   \n",
       "14989   demorous      1        0       1        463457         268386   \n",
       "14990   desidrat      1        0       1        463457         268386   \n",
       "14991  conhecems      1        0       1        463457         268386   \n",
       "14992   decadent      1        0       1        463457         268386   \n",
       "\n",
       "       f_right_minus  f_left_minus  f_right_norm  f_left_norm  \\\n",
       "20              -1.0     -0.999994           0.0     0.000006   \n",
       "37              -1.0     -0.999998           0.0     0.000002   \n",
       "61              -1.0     -0.999998           0.0     0.000002   \n",
       "95              -1.0     -0.999991           0.0     0.000009   \n",
       "113             -1.0     -0.999994           0.0     0.000006   \n",
       "...              ...           ...           ...          ...   \n",
       "14988           -1.0     -0.999998           0.0     0.000002   \n",
       "14989           -1.0     -0.999998           0.0     0.000002   \n",
       "14990           -1.0     -0.999998           0.0     0.000002   \n",
       "14991           -1.0     -0.999998           0.0     0.000002   \n",
       "14992           -1.0     -0.999998           0.0     0.000002   \n",
       "\n",
       "       f_right_minus_norm  f_left_minus_norm   pearson_quad  \n",
       "20              -0.000004          -0.000002       0.949910  \n",
       "37              -0.000004          -0.000002  293495.409252  \n",
       "61              -0.000004          -0.000002  293495.409252  \n",
       "95              -0.000004          -0.000002       0.844365  \n",
       "113             -0.000004          -0.000002       0.949910  \n",
       "...                   ...                ...            ...  \n",
       "14988           -0.000004          -0.000002  293495.409252  \n",
       "14989           -0.000004          -0.000002  293495.409252  \n",
       "14990           -0.000004          -0.000002  293495.409252  \n",
       "14991           -0.000004          -0.000002  293495.409252  \n",
       "14992           -0.000004          -0.000002  293495.409252  \n",
       "\n",
       "[7554 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a5ab6f8988138c4aafa838927270364e946a56a2b152cd75ab864ac6056d77"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
